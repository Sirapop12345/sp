{"metadata":{"colab":{"provenance":[{"file_id":"1fL4M2g0rRylybuEcqTJigCgH7-0Pjk0v","timestamp":1726244996253}],"collapsed_sections":["KZFFfEZBYFpf","WNnJYFXgffEY","tD1_TCjFQqbR","zlnLsiOORLOk","Xs5uc5kkSDVa","zxLStZU-SD_m","bPyMLrJ_SFuB"],"toc_visible":true,"mount_file_id":"1Y6yDkmq2ChgkmiWOkj0BQrzjmp332dc7","authorship_tag":"ABX9TyPv09BSPKhqIrTwD5pAL0JO"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07d2b3f6da78420aa6e886391348e25c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37f889bd8b284a45a9ae0fe8a7b7ccd4","IPY_MODEL_2b49dcacdae947c2b4a49fae02caa3c2","IPY_MODEL_15b318529d7c416bb4618971a6c89539"],"layout":"IPY_MODEL_f8bd34a21cba498bb24b6a45631c3c68"}},"37f889bd8b284a45a9ae0fe8a7b7ccd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7436340be80f4c55a0da4dae0d281b20","placeholder":"​","style":"IPY_MODEL_7e44de7c7d1a4520bed1b4efc07b7e62","value":"config.json: 100%"}},"2b49dcacdae947c2b4a49fae02caa3c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b29d32d84d994a48a072ee68042313c3","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3028f642364e4895bdb8665cdfd213ef","value":483}},"15b318529d7c416bb4618971a6c89539":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1af008ad0189405fba59c55a9dc8a7f4","placeholder":"​","style":"IPY_MODEL_321ab50ab7e04e0787fbf4ef443e5b4d","value":" 483/483 [00:00&lt;00:00, 30.0kB/s]"}},"f8bd34a21cba498bb24b6a45631c3c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7436340be80f4c55a0da4dae0d281b20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e44de7c7d1a4520bed1b4efc07b7e62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b29d32d84d994a48a072ee68042313c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3028f642364e4895bdb8665cdfd213ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1af008ad0189405fba59c55a9dc8a7f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"321ab50ab7e04e0787fbf4ef443e5b4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f37a36f03c1542ca877c867af4b3e13e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cd5875ab0734bf1870ed3c1f670eb51","IPY_MODEL_ccc7adbdb1144b6fa0f964b5f771ddc1","IPY_MODEL_1c40860e295742a986194a4d6e2f1769"],"layout":"IPY_MODEL_baf092e348a849119afb1886f87908ef"}},"7cd5875ab0734bf1870ed3c1f670eb51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9daf729df60414f948e2819217efbfd","placeholder":"​","style":"IPY_MODEL_3c183a90579a4b6787b4427d4656551f","value":"model.safetensors: 100%"}},"ccc7adbdb1144b6fa0f964b5f771ddc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8785f75c2bf844049cc3fcb4b057a0dd","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8eca75e89efa4846bc58a6f714d94640","value":267954768}},"1c40860e295742a986194a4d6e2f1769":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f1954fd1557492e9db8f1105aa5f1e0","placeholder":"​","style":"IPY_MODEL_60b8a9b3f12b469b8d3e9e056e573921","value":" 268M/268M [00:02&lt;00:00, 117MB/s]"}},"baf092e348a849119afb1886f87908ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9daf729df60414f948e2819217efbfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c183a90579a4b6787b4427d4656551f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8785f75c2bf844049cc3fcb4b057a0dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eca75e89efa4846bc58a6f714d94640":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f1954fd1557492e9db8f1105aa5f1e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60b8a9b3f12b469b8d3e9e056e573921":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdc51d79b3684e459e67cb8aef35c3de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51e92497811e46f79f3e8d9c898ec7f7","IPY_MODEL_79b2383da1f54e85a3c19f72cdf39174","IPY_MODEL_01c08f057fc24143b4a301f981718da6"],"layout":"IPY_MODEL_b16c4892c5984f78aa6fa53da74a32a9"}},"51e92497811e46f79f3e8d9c898ec7f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7b26d2c705a40848ba1cbbfe4a38fe7","placeholder":"​","style":"IPY_MODEL_3e92abc2826f4feabe96d9d8fe559b84","value":"tokenizer_config.json: 100%"}},"79b2383da1f54e85a3c19f72cdf39174":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbd9803896314142bbd55cb79ca5a3ea","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7dfe41eb447469ba86951dd02a32db1","value":48}},"01c08f057fc24143b4a301f981718da6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04ec1ec8678e4b9fbc7fe402adbe3dbb","placeholder":"​","style":"IPY_MODEL_e7fdb0522248449986fdf76ab263f104","value":" 48.0/48.0 [00:00&lt;00:00, 1.09kB/s]"}},"b16c4892c5984f78aa6fa53da74a32a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7b26d2c705a40848ba1cbbfe4a38fe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e92abc2826f4feabe96d9d8fe559b84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbd9803896314142bbd55cb79ca5a3ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7dfe41eb447469ba86951dd02a32db1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04ec1ec8678e4b9fbc7fe402adbe3dbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7fdb0522248449986fdf76ab263f104":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"063febd1a77142dd862fc03a66a98c42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40567428272c4f2ba9799b5e0dcb592c","IPY_MODEL_7bfd5439a9f94e77a1321428bf53e350","IPY_MODEL_5339d1fff380453cbb54b85a4dcd6faf"],"layout":"IPY_MODEL_6d842625b21644639451447bea69e8fc"}},"40567428272c4f2ba9799b5e0dcb592c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a63c7f4e4a460db8f837d5ee2da1fd","placeholder":"​","style":"IPY_MODEL_d3013207622c449792f2b8576a5710b7","value":"vocab.txt: 100%"}},"7bfd5439a9f94e77a1321428bf53e350":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb42731e20145fa98a5ef94743ea73a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf062e4420f4410eb761d75d6ffb0618","value":231508}},"5339d1fff380453cbb54b85a4dcd6faf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62f6d4a39c8e41378b3f60fb5510ceb4","placeholder":"​","style":"IPY_MODEL_9406115c901a4426b318ab95e6b57f88","value":" 232k/232k [00:00&lt;00:00, 4.48MB/s]"}},"6d842625b21644639451447bea69e8fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a63c7f4e4a460db8f837d5ee2da1fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3013207622c449792f2b8576a5710b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afb42731e20145fa98a5ef94743ea73a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf062e4420f4410eb761d75d6ffb0618":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62f6d4a39c8e41378b3f60fb5510ceb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9406115c901a4426b318ab95e6b57f88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24ec2b147d2245f999de27e71223c683":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0328b9de2bf48799ce11f421a152ce3","IPY_MODEL_0b0bd8918fac4cae91da2a45c18cfffe","IPY_MODEL_c7a2a13f53534eafabbc783f502277a7"],"layout":"IPY_MODEL_59043b9d47ba4366941a1200ef5b0b20"}},"a0328b9de2bf48799ce11f421a152ce3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be38c1df0cd04e00882bf0db57434dfd","placeholder":"​","style":"IPY_MODEL_dc1cff08a9794c00884f33044381e5db","value":"tokenizer.json: 100%"}},"0b0bd8918fac4cae91da2a45c18cfffe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11fd034c002e4d8c843e8b5069a9da6b","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d30530ca8a94bf9a5f4aaffc414c85a","value":466062}},"c7a2a13f53534eafabbc783f502277a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_846d0061d75a474890aaced856346d31","placeholder":"​","style":"IPY_MODEL_9840f472027f409693a47f6f389e2741","value":" 466k/466k [00:00&lt;00:00, 10.1MB/s]"}},"59043b9d47ba4366941a1200ef5b0b20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be38c1df0cd04e00882bf0db57434dfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc1cff08a9794c00884f33044381e5db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11fd034c002e4d8c843e8b5069a9da6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d30530ca8a94bf9a5f4aaffc414c85a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"846d0061d75a474890aaced856346d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9840f472027f409693a47f6f389e2741":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e337dcd644054aadb0fb4d161b6f9ac7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee2838e62c794d3d904b023f86754dc1","IPY_MODEL_4b09bb8b30b548e3847457af25644d83","IPY_MODEL_61171cad34c54c7cabb0af760d20a587"],"layout":"IPY_MODEL_176998289d3d4307a75ea152e8295edd"}},"ee2838e62c794d3d904b023f86754dc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7f93bd4130249df8bf03afd1da6e8cf","placeholder":"​","style":"IPY_MODEL_3c5fb2e9be564e15908d69ffc3f62c6b","value":"tokenizer_config.json: 100%"}},"4b09bb8b30b548e3847457af25644d83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8be6baba4a0462a97c15a980bb333e1","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b17fd0161b0349edb6cfdfe5d355d376","value":25}},"61171cad34c54c7cabb0af760d20a587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21d03440780f4400b5dff462baccd128","placeholder":"​","style":"IPY_MODEL_8975030a5fd247129a4c5f2b359c5c36","value":" 25.0/25.0 [00:00&lt;00:00, 532B/s]"}},"176998289d3d4307a75ea152e8295edd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7f93bd4130249df8bf03afd1da6e8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c5fb2e9be564e15908d69ffc3f62c6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8be6baba4a0462a97c15a980bb333e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b17fd0161b0349edb6cfdfe5d355d376":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21d03440780f4400b5dff462baccd128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8975030a5fd247129a4c5f2b359c5c36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cf4e98baf764e98b47a1a0df86639bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bff5c6fcd5f4ee6b58a501b3b2bb135","IPY_MODEL_b32ef277f1ba47408c2a16b6a03a3436","IPY_MODEL_4fc779f0ae7f464dbc9a83e17af4ee01"],"layout":"IPY_MODEL_70412a7c8fec4088b9d5cef238b17da0"}},"7bff5c6fcd5f4ee6b58a501b3b2bb135":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7e93c817b9443d38ac69ce17472e44e","placeholder":"​","style":"IPY_MODEL_a99ebb614dab47af9f6313094376d599","value":"vocab.json: 100%"}},"b32ef277f1ba47408c2a16b6a03a3436":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad1da6c652df42999e48353b60e2762b","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e4624295e0a47bebe7679689ada22e2","value":898823}},"4fc779f0ae7f464dbc9a83e17af4ee01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65b68359798d438a922eda9157985acb","placeholder":"​","style":"IPY_MODEL_03aa96c4a70946329bad33131a408e32","value":" 899k/899k [00:00&lt;00:00, 2.79MB/s]"}},"70412a7c8fec4088b9d5cef238b17da0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e93c817b9443d38ac69ce17472e44e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99ebb614dab47af9f6313094376d599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad1da6c652df42999e48353b60e2762b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4624295e0a47bebe7679689ada22e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65b68359798d438a922eda9157985acb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03aa96c4a70946329bad33131a408e32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99b54b4b17d541ffb349f11425566a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a99a50a74f964dd68b79f0cc0c1cf9d9","IPY_MODEL_e4e5318eb1b94194a92e956b76390b36","IPY_MODEL_22aa05cd932743648ad16b13096ceca8"],"layout":"IPY_MODEL_01613ffb80944c7ea2cc49f690a36a90"}},"a99a50a74f964dd68b79f0cc0c1cf9d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a8d3d6441924f759a52dbc6b23966d1","placeholder":"​","style":"IPY_MODEL_eae0ce29f3864372ba3f67e1673a7dc9","value":"merges.txt: 100%"}},"e4e5318eb1b94194a92e956b76390b36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca70668ad9134ed1ad1bf7d5695c83ed","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5edb6b7573644c9cad43176b799d8561","value":456318}},"22aa05cd932743648ad16b13096ceca8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cbc0a4c732546ca9469fbd7a29e7272","placeholder":"​","style":"IPY_MODEL_6680f42f2e6f45d1a00281b380217e0f","value":" 456k/456k [00:00&lt;00:00, 1.88MB/s]"}},"01613ffb80944c7ea2cc49f690a36a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a8d3d6441924f759a52dbc6b23966d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae0ce29f3864372ba3f67e1673a7dc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca70668ad9134ed1ad1bf7d5695c83ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5edb6b7573644c9cad43176b799d8561":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cbc0a4c732546ca9469fbd7a29e7272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6680f42f2e6f45d1a00281b380217e0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"064e0523dc6e40e4be4bb674d115ad72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1101f509fef4f788913b2b1d399af6c","IPY_MODEL_321579d846d143d998a13bd4f98a3a05","IPY_MODEL_8fbe446853d54b8fb09f0134f7e7ea8b"],"layout":"IPY_MODEL_c697dc2bef604525bb6a2baaabe8fb84"}},"d1101f509fef4f788913b2b1d399af6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42386a46180543be8536f685ccb8904e","placeholder":"​","style":"IPY_MODEL_9f35ad4f3a6644f18af8ab2a38f62119","value":"tokenizer.json: 100%"}},"321579d846d143d998a13bd4f98a3a05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ef6561356214dd99edf95d1bb2bcb63","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c55f55aff164ce590567d433c6efe24","value":1355863}},"8fbe446853d54b8fb09f0134f7e7ea8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_678cc680f0644beeb01ff25a697c68cf","placeholder":"​","style":"IPY_MODEL_c49ca8499a0c436eabb275f21c41f7fa","value":" 1.36M/1.36M [00:00&lt;00:00, 3.31MB/s]"}},"c697dc2bef604525bb6a2baaabe8fb84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42386a46180543be8536f685ccb8904e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f35ad4f3a6644f18af8ab2a38f62119":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ef6561356214dd99edf95d1bb2bcb63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c55f55aff164ce590567d433c6efe24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"678cc680f0644beeb01ff25a697c68cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c49ca8499a0c436eabb275f21c41f7fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f06df0a3636a454989b6f5642a6d8450":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de5cbe45657149b18bba4fda26a37847","IPY_MODEL_cf04b9831ce645f88dfdffb77829a18d","IPY_MODEL_a1163fb824ae44189840f23fab104197"],"layout":"IPY_MODEL_8860400fd81e4c1caad840872ba7172a"}},"de5cbe45657149b18bba4fda26a37847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5be4068cdd4f47fab7c125ef18a75e1e","placeholder":"​","style":"IPY_MODEL_198293a8b0e24c6580c174b13fffe18b","value":"config.json: 100%"}},"cf04b9831ce645f88dfdffb77829a18d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1cfd0b49254b318d113ee049dbe31e","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04fd2b6a20f14ddbba307ae8da52c14e","value":481}},"a1163fb824ae44189840f23fab104197":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_992e56a22230425b90843680e20a19ee","placeholder":"​","style":"IPY_MODEL_47a31b049307458ab0dc2b1ca9cbacfc","value":" 481/481 [00:00&lt;00:00, 14.3kB/s]"}},"8860400fd81e4c1caad840872ba7172a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5be4068cdd4f47fab7c125ef18a75e1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"198293a8b0e24c6580c174b13fffe18b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc1cfd0b49254b318d113ee049dbe31e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04fd2b6a20f14ddbba307ae8da52c14e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"992e56a22230425b90843680e20a19ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47a31b049307458ab0dc2b1ca9cbacfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3f4b5c8718541348fff4094632a7fdd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbc4c426b265491d99c71ac2f8fb6d29","IPY_MODEL_bf4280997d4d4888aa7ffc0d64dffa1a","IPY_MODEL_e5e109c5fb8944048581293cef147aad"],"layout":"IPY_MODEL_76fb1653b91b445ea0f070c781ddb987"}},"fbc4c426b265491d99c71ac2f8fb6d29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79cc175cc88443eb814938ef954cb7fd","placeholder":"​","style":"IPY_MODEL_bf739cbad0e04267bc1438422c9b6621","value":"model.safetensors: 100%"}},"bf4280997d4d4888aa7ffc0d64dffa1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce1886d58dce4b1f9e626a3c75794f0e","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2100ed0f257475ab7fb452f75edd9c9","value":498818054}},"e5e109c5fb8944048581293cef147aad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c32b9e0504244a1682b90f413cb10f7e","placeholder":"​","style":"IPY_MODEL_dc3a2568a93442408fbbdb57d712aed8","value":" 499M/499M [00:04&lt;00:00, 96.6MB/s]"}},"76fb1653b91b445ea0f070c781ddb987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79cc175cc88443eb814938ef954cb7fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf739cbad0e04267bc1438422c9b6621":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce1886d58dce4b1f9e626a3c75794f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2100ed0f257475ab7fb452f75edd9c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c32b9e0504244a1682b90f413cb10f7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc3a2568a93442408fbbdb57d712aed8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df63c69c724342fbb88a93490b95c110":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36184cd576324e44ae3f952963618024","IPY_MODEL_632f4511381349a8ad697d7fdf2608c9","IPY_MODEL_45ed83dda15542459bbd0592aa9088dd"],"layout":"IPY_MODEL_06ac108144ff4fbf867a8a72cf9e7471"}},"36184cd576324e44ae3f952963618024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90b6a6c731d643c885d6824d34ed2928","placeholder":"​","style":"IPY_MODEL_798c3c8c9b724dcd9c190860d01eebce","value":"config.json: 100%"}},"632f4511381349a8ad697d7fdf2608c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3da61f8d29f3421face351bddace0299","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_968ede3a2f1042c885627cafa99f74ed","value":760}},"45ed83dda15542459bbd0592aa9088dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad4ab2ba07f4073b659456822831709","placeholder":"​","style":"IPY_MODEL_6a793d0b97f54357a5afeb3d774d3935","value":" 760/760 [00:00&lt;00:00, 16.0kB/s]"}},"06ac108144ff4fbf867a8a72cf9e7471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b6a6c731d643c885d6824d34ed2928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"798c3c8c9b724dcd9c190860d01eebce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3da61f8d29f3421face351bddace0299":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968ede3a2f1042c885627cafa99f74ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dad4ab2ba07f4073b659456822831709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a793d0b97f54357a5afeb3d774d3935":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"789adcada9fd414c9262a84f3c8cbda7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e42c1b4cdf5477789b726f5d43ded25","IPY_MODEL_a244ae4cb8104390a66faa02ff243b72","IPY_MODEL_59a65969b6994bc689df86c295d00785"],"layout":"IPY_MODEL_7ed0cd74c0ac4a37bdc157e6dc973c68"}},"4e42c1b4cdf5477789b726f5d43ded25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f06dfe32ef44479be3a5206c54aaf75","placeholder":"​","style":"IPY_MODEL_acc8caf33def4368b254b6db938757ae","value":"pytorch_model.bin: 100%"}},"a244ae4cb8104390a66faa02ff243b72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcbc83a50d004abfa421b7c573a09a1a","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f832f7873a741308575e5e58c6c67c2","value":467042463}},"59a65969b6994bc689df86c295d00785":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38db9badf7194f95aa5fda60f748fd25","placeholder":"​","style":"IPY_MODEL_670fd28d244c4430a9d803f4ff411bc3","value":" 467M/467M [00:03&lt;00:00, 157MB/s]"}},"7ed0cd74c0ac4a37bdc157e6dc973c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f06dfe32ef44479be3a5206c54aaf75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acc8caf33def4368b254b6db938757ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcbc83a50d004abfa421b7c573a09a1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f832f7873a741308575e5e58c6c67c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38db9badf7194f95aa5fda60f748fd25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"670fd28d244c4430a9d803f4ff411bc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16eefa5766644eb38f3adb530352ebe1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_765d68b3a64e4c63aa84675cc39d8d20","IPY_MODEL_841cfc728e7248c98deb372d38927e7b","IPY_MODEL_eaee0b7ecb284a9c91053060c197f4ff"],"layout":"IPY_MODEL_d04fef3813d045c99d06d7659990a776"}},"765d68b3a64e4c63aa84675cc39d8d20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62aa07e1bafd4c269d2a8c76789a50e5","placeholder":"​","style":"IPY_MODEL_975f10b92de64fef8a9a0f5b070bdae0","value":"spiece.model: 100%"}},"841cfc728e7248c98deb372d38927e7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c1ec72d49424a7fb4ff63c1874762b1","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dc0c41b9b56499e8caf283444b0636d","value":798011}},"eaee0b7ecb284a9c91053060c197f4ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e541683542ce4cf9af1a6c32fc808331","placeholder":"​","style":"IPY_MODEL_aafaeb1c444d46e5bef550d61889fae6","value":" 798k/798k [00:00&lt;00:00, 2.43MB/s]"}},"d04fef3813d045c99d06d7659990a776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62aa07e1bafd4c269d2a8c76789a50e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"975f10b92de64fef8a9a0f5b070bdae0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c1ec72d49424a7fb4ff63c1874762b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dc0c41b9b56499e8caf283444b0636d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e541683542ce4cf9af1a6c32fc808331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aafaeb1c444d46e5bef550d61889fae6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8ac3e00fa984f18a3529168c805cc42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dcf1cf689d043c3a3e04adeae366877","IPY_MODEL_fbd0d965856b43e68e92a6dcf49ca2b7","IPY_MODEL_703efc9d37be45f2b0cef672ef75242c"],"layout":"IPY_MODEL_f85b0edbf24c49bab4b58ebda65b27b4"}},"7dcf1cf689d043c3a3e04adeae366877":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b54ce5b89e50453ea2a8795755b45958","placeholder":"​","style":"IPY_MODEL_9cde3488eec141a887214237a638e096","value":"tokenizer.json: 100%"}},"fbd0d965856b43e68e92a6dcf49ca2b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fa92cb8a7a44333bf9da906f4348407","max":1382015,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26871be981ed4b1985d96202c252ea10","value":1382015}},"703efc9d37be45f2b0cef672ef75242c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddbd5683b83a4c96a5e4276f8e20be9e","placeholder":"​","style":"IPY_MODEL_593c1ae59fc54c4ab93af2c72c231c0d","value":" 1.38M/1.38M [00:00&lt;00:00, 4.21MB/s]"}},"f85b0edbf24c49bab4b58ebda65b27b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b54ce5b89e50453ea2a8795755b45958":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cde3488eec141a887214237a638e096":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fa92cb8a7a44333bf9da906f4348407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26871be981ed4b1985d96202c252ea10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddbd5683b83a4c96a5e4276f8e20be9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"593c1ae59fc54c4ab93af2c72c231c0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd698aac198c40be9ab3f73418cba61b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57c4c26b556d48dbabb8b48dd9ac701c","IPY_MODEL_88a501fc3a38471cb1cf0d695b6e8863","IPY_MODEL_1c5f7e5b82254bda918b8effcad7174f"],"layout":"IPY_MODEL_e086f6713fe848ae85167b90d2ceebca"}},"57c4c26b556d48dbabb8b48dd9ac701c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ba9b781ee5b49b1929612342d8d4b78","placeholder":"​","style":"IPY_MODEL_7a0be6543e774f05b87b7b1c4925a4cb","value":"vocab.json: 100%"}},"88a501fc3a38471cb1cf0d695b6e8863":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29da7ff51fb4ef38c1e5c2cbecc840f","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_111df05df371458b9291d9fa0fe280b3","value":898823}},"1c5f7e5b82254bda918b8effcad7174f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968cd9b4762449ac845c22986bde3d46","placeholder":"​","style":"IPY_MODEL_1bce1184bd324a54b0150a586d3f0d82","value":" 899k/899k [00:00&lt;00:00, 2.74MB/s]"}},"e086f6713fe848ae85167b90d2ceebca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ba9b781ee5b49b1929612342d8d4b78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a0be6543e774f05b87b7b1c4925a4cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29da7ff51fb4ef38c1e5c2cbecc840f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"111df05df371458b9291d9fa0fe280b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"968cd9b4762449ac845c22986bde3d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bce1184bd324a54b0150a586d3f0d82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a74f9d87f695434289b1d950f35bda4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3188f44e42574908b11bcc35debc3556","IPY_MODEL_8b49d14e52ba43659c02cae97cdb20d2","IPY_MODEL_c49deae9c3c34d85b4f7ffc51349775d"],"layout":"IPY_MODEL_13d0b5547cad4cab93c4de80f2179e6a"}},"3188f44e42574908b11bcc35debc3556":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d237da2ee944257b5db659b36c81266","placeholder":"​","style":"IPY_MODEL_8278795127684ab4878db1a6d634e63f","value":"merges.txt: 100%"}},"8b49d14e52ba43659c02cae97cdb20d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7e810c0fa645ec8cfb64bc8a104ad8","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1773ef07fff444029a0090200c59e14b","value":456318}},"c49deae9c3c34d85b4f7ffc51349775d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_801e28b6bea84629925098534f0c8614","placeholder":"​","style":"IPY_MODEL_f46d518f6cdb44cd99d61d6e288c40e8","value":" 456k/456k [00:00&lt;00:00, 1.90MB/s]"}},"13d0b5547cad4cab93c4de80f2179e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d237da2ee944257b5db659b36c81266":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8278795127684ab4878db1a6d634e63f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c7e810c0fa645ec8cfb64bc8a104ad8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1773ef07fff444029a0090200c59e14b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"801e28b6bea84629925098534f0c8614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46d518f6cdb44cd99d61d6e288c40e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d49f794ac624903ae67292c04295ee9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78380aa9836849fbb40ff31be28aa30d","IPY_MODEL_eafbeb7aecfc4b30b5d3d6d81162bb94","IPY_MODEL_039c8cf3fd634607bee706a0df38bacc"],"layout":"IPY_MODEL_84c42baac46d438f885f6453038967d5"}},"78380aa9836849fbb40ff31be28aa30d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b041902497ee40a9977ad4c1db8739df","placeholder":"​","style":"IPY_MODEL_9d93eeb89d814ad6b1de0e9ac5f768a4","value":"tokenizer.json: 100%"}},"eafbeb7aecfc4b30b5d3d6d81162bb94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac6ba53bc9794279b5e119b4538a46ba","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b71866b5aef4e96b2011b6c2f87a761","value":1355863}},"039c8cf3fd634607bee706a0df38bacc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7df8a7a4bd4c40b5b8dd298105498fb3","placeholder":"​","style":"IPY_MODEL_8f1d9d7012bb43d8a7e07252115d4a4b","value":" 1.36M/1.36M [00:00&lt;00:00, 2.80MB/s]"}},"84c42baac46d438f885f6453038967d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b041902497ee40a9977ad4c1db8739df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d93eeb89d814ad6b1de0e9ac5f768a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac6ba53bc9794279b5e119b4538a46ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b71866b5aef4e96b2011b6c2f87a761":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7df8a7a4bd4c40b5b8dd298105498fb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f1d9d7012bb43d8a7e07252115d4a4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c71bc8105eb744418415cf80a0bca318":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5069af5ddc4646469f22dac5c66c0c5c","IPY_MODEL_5b7f8cc85b794e559b4e06cc98aeda38","IPY_MODEL_f3c704c21ba74e4fa3714848096d418f"],"layout":"IPY_MODEL_e9913a1416784811b255c42575a61678"}},"5069af5ddc4646469f22dac5c66c0c5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28e1e93cb81649ca992ef4478eb2b9a1","placeholder":"​","style":"IPY_MODEL_416e90c4fce54364b646218b65d06373","value":"config.json: 100%"}},"5b7f8cc85b794e559b4e06cc98aeda38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_354cf1af785a4485ae8b9e64730bc972","max":694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da8c1b478d8f4af184830aa083168e30","value":694}},"f3c704c21ba74e4fa3714848096d418f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb1cd05c58246cc9d05e3f636979912","placeholder":"​","style":"IPY_MODEL_9308cd29d0224ae991604144f69c3e3b","value":" 694/694 [00:00&lt;00:00, 9.57kB/s]"}},"e9913a1416784811b255c42575a61678":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28e1e93cb81649ca992ef4478eb2b9a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416e90c4fce54364b646218b65d06373":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"354cf1af785a4485ae8b9e64730bc972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da8c1b478d8f4af184830aa083168e30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afb1cd05c58246cc9d05e3f636979912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9308cd29d0224ae991604144f69c3e3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddec840c0cb0470d9a9e1b4e459d5db8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f9356e7a2d34c75802e539e210f18cc","IPY_MODEL_5fe7a13a5f9d4302b5138a7ef95ac24b","IPY_MODEL_c8f2cd753475466fa6a887b19136e9a4"],"layout":"IPY_MODEL_45118e3b04894d00921afbce1dbe04dc"}},"2f9356e7a2d34c75802e539e210f18cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ed7b6bbd488434a8eb29d6c4d1a434e","placeholder":"​","style":"IPY_MODEL_37c535f528ba4526a04e35b18fb4f9e4","value":"pytorch_model.bin: 100%"}},"5fe7a13a5f9d4302b5138a7ef95ac24b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3979387eec814123a3d6284358704c46","max":597257159,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4942a6a865eb45d4bb9fb3b4b94635b5","value":597257159}},"c8f2cd753475466fa6a887b19136e9a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_226543d95ae442a2af6b0f2c10f3d79f","placeholder":"​","style":"IPY_MODEL_035c19b2f8374441a665d7a5c7060cf9","value":" 597M/597M [00:06&lt;00:00, 27.5MB/s]"}},"45118e3b04894d00921afbce1dbe04dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ed7b6bbd488434a8eb29d6c4d1a434e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c535f528ba4526a04e35b18fb4f9e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3979387eec814123a3d6284358704c46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4942a6a865eb45d4bb9fb3b4b94635b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"226543d95ae442a2af6b0f2c10f3d79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"035c19b2f8374441a665d7a5c7060cf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9393757,"sourceType":"datasetVersion","datasetId":5700932}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Testing Fine-tuning & Data Preparation method**\n\n> Now we want to make sure that our method is appropriate for our senior project\n\n- LoRA fine-tuning or Freezing Layer or Full-parameter fine-tuning.\n- Deleting the AI-Generated structure will effect the performance or not.\n- Data Preparation like lowercase or delete the stop word will effect the performance or not\n\n","metadata":{"id":"8TZ5MqFP9ub0"}},{"cell_type":"markdown","source":"# Import dataset and library","metadata":{"id":"QbGsCuha-vhu"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"id":"j4KXBkNg9lsO","executionInfo":{"status":"ok","timestamp":1726306767342,"user_tz":-420,"elapsed":2480,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:18.800713Z","iopub.execute_input":"2024-09-14T14:23:18.801113Z","iopub.status.idle":"2024-09-14T14:23:19.176138Z","shell.execute_reply.started":"2024-09-14T14:23:18.801072Z","shell.execute_reply":"2024-09-14T14:23:19.175373Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/original/original_dataset.csv')\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"i5aqw5o3m4eP","executionInfo":{"status":"ok","timestamp":1726306773057,"user_tz":-420,"elapsed":5718,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"961e4642-cf3e-4f66-97c2-6b3990825449","execution":{"iopub.status.busy":"2024-09-14T14:23:19.177585Z","iopub.execute_input":"2024-09-14T14:23:19.177937Z","iopub.status.idle":"2024-09-14T14:23:22.723781Z","shell.execute_reply.started":"2024-09-14T14:23:19.177907Z","shell.execute_reply":"2024-09-14T14:23:22.722710Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text  label  \\\n0  Phones\\n\\nModern humans today are always on th...      0   \n1  This essay will explain if drivers should or s...      0   \n2  Driving while the use of cellular devices\\n\\nT...      0   \n3  Phones & Driving\\n\\nDrivers should not be able...      0   \n4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n\n          prompt_name           source  RDizzl3_seven  \n0  Phones and driving  persuade_corpus          False  \n1  Phones and driving  persuade_corpus          False  \n2  Phones and driving  persuade_corpus          False  \n3  Phones and driving  persuade_corpus          False  \n4  Phones and driving  persuade_corpus          False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df[['text','label']]\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"t4yAGm4Lm-VS","executionInfo":{"status":"ok","timestamp":1726306774296,"user_tz":-420,"elapsed":1243,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"d25cefda-084b-46ce-fced-40a1a92597c5","execution":{"iopub.status.busy":"2024-09-14T14:23:22.725424Z","iopub.execute_input":"2024-09-14T14:23:22.725726Z","iopub.status.idle":"2024-09-14T14:23:22.740069Z","shell.execute_reply.started":"2024-09-14T14:23:22.725693Z","shell.execute_reply":"2024-09-14T14:23:22.739158Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Phones\\n\\nModern humans today are always on th...      0\n1  This essay will explain if drivers should or s...      0\n2  Driving while the use of cellular devices\\n\\nT...      0\n3  Phones & Driving\\n\\nDrivers should not be able...      0\n4  Cell Phone Operation While Driving\\n\\nThe abil...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Delete Duplicate row and missing values","metadata":{"id":"qvn_lYuyRn-x"}},{"cell_type":"code","source":"#Check many possible ways that It will be null\n\ndf[df['text'].isnull()].head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"5rKmMpPkRsRm","executionInfo":{"status":"ok","timestamp":1726306774297,"user_tz":-420,"elapsed":12,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"3af491b6-cca0-491b-b90b-e8b5c9bb3c1b","execution":{"iopub.status.busy":"2024-09-14T14:23:22.742576Z","iopub.execute_input":"2024-09-14T14:23:22.742946Z","iopub.status.idle":"2024-09-14T14:23:22.763480Z","shell.execute_reply.started":"2024-09-14T14:23:22.742904Z","shell.execute_reply":"2024-09-14T14:23:22.762317Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      text  label\n44918  NaN      1\n44944  NaN      1\n45059  NaN      1\n45074  NaN      1\n45089  NaN      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44918</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44944</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45059</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45074</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45089</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[df['text'].apply(lambda x: isinstance(x, str) and x.strip() == '')].head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"1e57lZAwRsWg","executionInfo":{"status":"ok","timestamp":1726306774297,"user_tz":-420,"elapsed":10,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"d6787530-857f-45a3-e8c0-272e2e734609","execution":{"iopub.status.busy":"2024-09-14T14:23:22.764976Z","iopub.execute_input":"2024-09-14T14:23:22.765378Z","iopub.status.idle":"2024-09-14T14:23:22.830025Z","shell.execute_reply.started":"2024-09-14T14:23:22.765343Z","shell.execute_reply":"2024-09-14T14:23:22.829050Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        text  label\n44920   \\n\\n      1\n44936   \\n\\n      1\n45169   \\n\\n      1\n45275             1\n45475  \\n\\n       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44920</th>\n      <td>\\n\\n</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44936</th>\n      <td>\\n\\n</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45169</th>\n      <td>\\n\\n</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45275</th>\n      <td></td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45475</th>\n      <td>\\n\\n</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop rows where 'text' is NaN or None\ndf = df.dropna(subset=['text'])\n\n# Drop rows where 'text' is an empty string or whitespace\ndf = df[df['text'].str.strip() != '']","metadata":{"id":"ooe3edpFR3VW","executionInfo":{"status":"ok","timestamp":1726306774297,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:22.831199Z","iopub.execute_input":"2024-09-14T14:23:22.831490Z","iopub.status.idle":"2024-09-14T14:23:23.003180Z","shell.execute_reply.started":"2024-09-14T14:23:22.831459Z","shell.execute_reply":"2024-09-14T14:23:23.001830Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Checking that there is no more missing value\ndf.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L986aG4aR6a3","executionInfo":{"status":"ok","timestamp":1726306774812,"user_tz":-420,"elapsed":523,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"19736e63-1cb8-462c-8c15-0b1cc161a090","execution":{"iopub.status.busy":"2024-09-14T14:23:23.009674Z","iopub.execute_input":"2024-09-14T14:23:23.013229Z","iopub.status.idle":"2024-09-14T14:23:23.059723Z","shell.execute_reply.started":"2024-09-14T14:23:23.013161Z","shell.execute_reply":"2024-09-14T14:23:23.058264Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 65328 entries, 0 to 65507\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    65328 non-null  object\n 1   label   65328 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 1.5+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Detect duplicates that in our dataset has duplicated or not.\ndf[df.duplicated() == True].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOrjQAx8R9y1","executionInfo":{"status":"ok","timestamp":1726306774812,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"2de600e0-eaae-41e6-97ed-2de589cc34fc","execution":{"iopub.status.busy":"2024-09-14T14:23:23.061464Z","iopub.execute_input":"2024-09-14T14:23:23.062296Z","iopub.status.idle":"2024-09-14T14:23:23.454959Z","shell.execute_reply.started":"2024-09-14T14:23:23.062231Z","shell.execute_reply":"2024-09-14T14:23:23.453688Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(0, 2)"},"metadata":{}}]},{"cell_type":"code","source":"#There are '\\n' in most of essays. The reason maybe that It is new line (ขึ้นบรรทัดใหม่)\ndf[df['text'].str.contains('\\n') == True].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMOEEtdSTsTP","executionInfo":{"status":"ok","timestamp":1726306775338,"user_tz":-420,"elapsed":529,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"3f4717a5-0b3c-4305-cb11-870acdcccc14","execution":{"iopub.status.busy":"2024-09-14T14:23:23.457908Z","iopub.execute_input":"2024-09-14T14:23:23.458346Z","iopub.status.idle":"2024-09-14T14:23:23.537285Z","shell.execute_reply.started":"2024-09-14T14:23:23.458298Z","shell.execute_reply":"2024-09-14T14:23:23.536350Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(63463, 2)"},"metadata":{}}]},{"cell_type":"code","source":"#There are '\\n' in most of essays. The reason maybe that It is new line (ขึ้นบรรทัดใหม่)\ndf[df['text'].str.contains('\\r') == True].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evjiKUFLT_x3","executionInfo":{"status":"ok","timestamp":1726306775338,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"c4b6e2b7-4f4c-4ab9-94df-9e8a255ab2eb","execution":{"iopub.status.busy":"2024-09-14T14:23:23.540867Z","iopub.execute_input":"2024-09-14T14:23:23.541214Z","iopub.status.idle":"2024-09-14T14:23:23.649262Z","shell.execute_reply.started":"2024-09-14T14:23:23.541181Z","shell.execute_reply":"2024-09-14T14:23:23.648321Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(220, 2)"},"metadata":{}}]},{"cell_type":"code","source":"#There are '\\n' in most of essays. The reason maybe that It is new line (ขึ้นบรรทัดใหม่)\ndf[df['text'].str.contains('\\t') == True].shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_v_SPSjZUEDF","executionInfo":{"status":"ok","timestamp":1726306775827,"user_tz":-420,"elapsed":492,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"911fbfd9-4a69-4b37-cf69-44c6630172b3","execution":{"iopub.status.busy":"2024-09-14T14:23:23.650496Z","iopub.execute_input":"2024-09-14T14:23:23.650836Z","iopub.status.idle":"2024-09-14T14:23:23.758216Z","shell.execute_reply.started":"2024-09-14T14:23:23.650805Z","shell.execute_reply":"2024-09-14T14:23:23.757147Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(1, 2)"},"metadata":{}}]},{"cell_type":"code","source":"#We try to replace '\\n' with ' '\ndf['text'] = df['text'].str.replace('\\n', ' ', regex=False)\ndf['text'] = df['text'].str.replace('\\r', ' ', regex=False)\ndf['text'] = df['text'].str.replace('\\t', ' ', regex=False)\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ps5-o_ueUF9N","executionInfo":{"status":"ok","timestamp":1726306779105,"user_tz":-420,"elapsed":3280,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"70505358-a146-4864-8f7e-c42b820cf738","execution":{"iopub.status.busy":"2024-09-14T14:23:23.759486Z","iopub.execute_input":"2024-09-14T14:23:23.759864Z","iopub.status.idle":"2024-09-14T14:23:24.022496Z","shell.execute_reply.started":"2024-09-14T14:23:23.759821Z","shell.execute_reply":"2024-09-14T14:23:24.021496Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Phones  Modern humans today are always on thei...      0\n1  This essay will explain if drivers should or s...      0\n2  Driving while the use of cellular devices  Tod...      0\n3  Phones & Driving  Drivers should not be able t...      0\n4  Cell Phone Operation While Driving  The abilit...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones  Modern humans today are always on thei...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices  Tod...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving  Drivers should not be able t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving  The abilit...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#df.to_csv('no_missing_dataset.csv',index = False)","metadata":{"id":"AWnZSxfmSFIn","executionInfo":{"status":"ok","timestamp":1726306779106,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:24.026397Z","iopub.execute_input":"2024-09-14T14:23:24.026959Z","iopub.status.idle":"2024-09-14T14:23:24.031035Z","shell.execute_reply.started":"2024-09-14T14:23:24.026925Z","shell.execute_reply":"2024-09-14T14:23:24.029978Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8b5CpO0Qg3j","executionInfo":{"status":"ok","timestamp":1726306779106,"user_tz":-420,"elapsed":7,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"f0a37406-f526-4328-9bb6-ad7bc622599b","execution":{"iopub.status.busy":"2024-09-14T14:23:24.032050Z","iopub.execute_input":"2024-09-14T14:23:24.032332Z","iopub.status.idle":"2024-09-14T14:23:24.046011Z","shell.execute_reply.started":"2024-09-14T14:23:24.032293Z","shell.execute_reply":"2024-09-14T14:23:24.045012Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(65328, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df.reset_index(drop=True, inplace=True)","metadata":{"id":"cBElw5N2qLMZ","executionInfo":{"status":"ok","timestamp":1726306779106,"user_tz":-420,"elapsed":7,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:24.047385Z","iopub.execute_input":"2024-09-14T14:23:24.047708Z","iopub.status.idle":"2024-09-14T14:23:24.052347Z","shell.execute_reply.started":"2024-09-14T14:23:24.047664Z","shell.execute_reply":"2024-09-14T14:23:24.051333Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"s0f45ipOvmMq","executionInfo":{"status":"ok","timestamp":1726306782281,"user_tz":-420,"elapsed":3181,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"c67f9025-97a3-46f7-fe6e-56fa0aa8576c","execution":{"iopub.status.busy":"2024-09-14T14:23:24.055108Z","iopub.execute_input":"2024-09-14T14:23:24.055726Z","iopub.status.idle":"2024-09-14T14:23:24.066432Z","shell.execute_reply.started":"2024-09-14T14:23:24.055682Z","shell.execute_reply":"2024-09-14T14:23:24.065409Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Phones  Modern humans today are always on thei...      0\n1  This essay will explain if drivers should or s...      0\n2  Driving while the use of cellular devices  Tod...      0\n3  Phones & Driving  Drivers should not be able t...      0\n4  Cell Phone Operation While Driving  The abilit...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones  Modern humans today are always on thei...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices  Tod...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving  Drivers should not be able t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving  The abilit...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1.1 AI-deleted dataset","metadata":{"id":"ubk-_04pO3SO"}},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/original/final_cleaned (1).csv')\ndf1.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"XGdl7FB--2is","executionInfo":{"status":"ok","timestamp":1726306787773,"user_tz":-420,"elapsed":5495,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"56a3dd28-ee72-4e17-ae45-e77783968b73","execution":{"iopub.status.busy":"2024-09-14T14:23:24.067655Z","iopub.execute_input":"2024-09-14T14:23:24.068015Z","iopub.status.idle":"2024-09-14T14:23:27.829876Z","shell.execute_reply.started":"2024-09-14T14:23:24.067955Z","shell.execute_reply":"2024-09-14T14:23:27.829032Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                text  label  \\\n0  Phones Modern humans today are always on their...      0   \n1  This essay will explain if drivers should or s...      0   \n2  Driving while the use of cellular devices Toda...      0   \n3  Phones & Driving Drivers should not be able to...      0   \n4  Cell Phone Operation While Driving The ability...      0   \n\n          prompt_name           source  \n0  Phones and driving  persuade_corpus  \n1  Phones and driving  persuade_corpus  \n2  Phones and driving  persuade_corpus  \n3  Phones and driving  persuade_corpus  \n4  Phones and driving  persuade_corpus  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones Modern humans today are always on their...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices Toda...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving Drivers should not be able to...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving The ability...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1 = df1[['text','label']]\ndf1.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"oF2GBpM4mh1Z","executionInfo":{"status":"ok","timestamp":1726306789608,"user_tz":-420,"elapsed":1838,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"9b225608-7942-4534-953a-6c3daa40c2fd","execution":{"iopub.status.busy":"2024-09-14T14:23:27.831259Z","iopub.execute_input":"2024-09-14T14:23:27.831641Z","iopub.status.idle":"2024-09-14T14:23:27.842905Z","shell.execute_reply.started":"2024-09-14T14:23:27.831597Z","shell.execute_reply":"2024-09-14T14:23:27.841936Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Phones Modern humans today are always on their...      0\n1  This essay will explain if drivers should or s...      0\n2  Driving while the use of cellular devices Toda...      0\n3  Phones & Driving Drivers should not be able to...      0\n4  Cell Phone Operation While Driving The ability...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones Modern humans today are always on their...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices Toda...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving Drivers should not be able to...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving The ability...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1.2 Lowercase all text dataset","metadata":{"id":"4hwd7mfQUf9V"}},{"cell_type":"code","source":"df2 = df.copy()","metadata":{"id":"GOrmNGwtUya7","executionInfo":{"status":"ok","timestamp":1726306789608,"user_tz":-420,"elapsed":4,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:27.844009Z","iopub.execute_input":"2024-09-14T14:23:27.844331Z","iopub.status.idle":"2024-09-14T14:23:27.850805Z","shell.execute_reply.started":"2024-09-14T14:23:27.844298Z","shell.execute_reply":"2024-09-14T14:23:27.850024Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Lowercase the data in 'text_column'\ndf2['text'] = df2['text'].str.lower()\n\ndf2.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"-frVYBUzOnZf","executionInfo":{"status":"ok","timestamp":1726306792433,"user_tz":-420,"elapsed":2828,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"f1679820-a866-4b2d-8c9f-aefd564493d0","execution":{"iopub.status.busy":"2024-09-14T14:23:27.852157Z","iopub.execute_input":"2024-09-14T14:23:27.852931Z","iopub.status.idle":"2024-09-14T14:23:28.471498Z","shell.execute_reply.started":"2024-09-14T14:23:27.852889Z","shell.execute_reply":"2024-09-14T14:23:28.470407Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  phones  modern humans today are always on thei...      0\n1  this essay will explain if drivers should or s...      0\n2  driving while the use of cellular devices  tod...      0\n3  phones & driving  drivers should not be able t...      0\n4  cell phone operation while driving  the abilit...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>phones  modern humans today are always on thei...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>this essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>driving while the use of cellular devices  tod...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>phones &amp; driving  drivers should not be able t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cell phone operation while driving  the abilit...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1.3 Removing all Punctuation & Special Characters","metadata":{"id":"mvCnm8hoUm3d"}},{"cell_type":"code","source":"df3 = df.copy()","metadata":{"id":"EnzaVg_hUzNw","executionInfo":{"status":"ok","timestamp":1726306792433,"user_tz":-420,"elapsed":14,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:28.473095Z","iopub.execute_input":"2024-09-14T14:23:28.473476Z","iopub.status.idle":"2024-09-14T14:23:28.479946Z","shell.execute_reply.started":"2024-09-14T14:23:28.473433Z","shell.execute_reply":"2024-09-14T14:23:28.479033Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#library that contains punctuation\nimport string\nstring.punctuation","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"b8Rpkr1YQpo-","executionInfo":{"status":"ok","timestamp":1726306792433,"user_tz":-420,"elapsed":13,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"3450b8ba-0177-4af0-8852-3a7f6da6ac9b","execution":{"iopub.status.busy":"2024-09-14T14:23:28.481496Z","iopub.execute_input":"2024-09-14T14:23:28.481796Z","iopub.status.idle":"2024-09-14T14:23:28.491215Z","shell.execute_reply.started":"2024-09-14T14:23:28.481765Z","shell.execute_reply":"2024-09-14T14:23:28.490102Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"},"metadata":{}}]},{"cell_type":"code","source":"#defining the function to remove punctuation\ndef remove_punctuation(text):\n    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree","metadata":{"id":"G7oRqAE0QuJL","executionInfo":{"status":"ok","timestamp":1726306792433,"user_tz":-420,"elapsed":12,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:28.492665Z","iopub.execute_input":"2024-09-14T14:23:28.493227Z","iopub.status.idle":"2024-09-14T14:23:28.500039Z","shell.execute_reply.started":"2024-09-14T14:23:28.493184Z","shell.execute_reply":"2024-09-14T14:23:28.499030Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df3['text'].apply(str)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"9hHoZYuenO-j","executionInfo":{"status":"ok","timestamp":1726306792433,"user_tz":-420,"elapsed":11,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"e087581b-a085-40c3-b9fe-0c4f9411b717","execution":{"iopub.status.busy":"2024-09-14T14:23:28.501381Z","iopub.execute_input":"2024-09-14T14:23:28.501735Z","iopub.status.idle":"2024-09-14T14:23:28.532866Z","shell.execute_reply.started":"2024-09-14T14:23:28.501696Z","shell.execute_reply":"2024-09-14T14:23:28.531807Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0        Phones  Modern humans today are always on thei...\n1        This essay will explain if drivers should or s...\n2        Driving while the use of cellular devices  Tod...\n3        Phones & Driving  Drivers should not be able t...\n4        Cell Phone Operation While Driving  The abilit...\n                               ...                        \n65323      Dear Senator,  I am writing to you regarding...\n65324      I remember the day distinctively. I was sitt...\n65325      Dear Senator,   I am writing this letter to ...\n65326      Dear Senator,  I am writing to urge you to e...\n65327      It was a typical summer afternoon in my home...\nName: text, Length: 65328, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#storing the puntuation free text\ndf3['text']= df3['text'].apply(lambda x:remove_punctuation(x))\ndf3.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"RBzzJBh-QuaT","executionInfo":{"status":"ok","timestamp":1726306819301,"user_tz":-420,"elapsed":26878,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"528a2e6a-0a45-45b3-a491-43d65367fc1a","execution":{"iopub.status.busy":"2024-09-14T14:23:28.534093Z","iopub.execute_input":"2024-09-14T14:23:28.534446Z","iopub.status.idle":"2024-09-14T14:23:49.995902Z","shell.execute_reply.started":"2024-09-14T14:23:28.534398Z","shell.execute_reply":"2024-09-14T14:23:49.994896Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Phones  Modern humans today are always on thei...      0\n1  This essay will explain if drivers should or s...      0\n2  Driving while the use of cellular devices  Tod...      0\n3  Phones  Driving  Drivers should not be able to...      0\n4  Cell Phone Operation While Driving  The abilit...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones  Modern humans today are always on thei...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices  Tod...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones  Driving  Drivers should not be able to...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving  The abilit...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Comparing all 4 types of dataset","metadata":{"id":"Mp3SQNDATMsZ"}},{"cell_type":"markdown","source":"## Training / Validation / Test set split","metadata":{"id":"SQN5e6cDX-OG"}},{"cell_type":"code","source":"print(df.shape)\nprint(df1.shape)\nprint(df2.shape)\nprint(df3.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_k9AHkzTRBk","executionInfo":{"status":"ok","timestamp":1726306819302,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"e212cb84-624d-4cef-ddc4-ae4f47a90d7f","execution":{"iopub.status.busy":"2024-09-14T14:23:49.997216Z","iopub.execute_input":"2024-09-14T14:23:49.997539Z","iopub.status.idle":"2024-09-14T14:23:50.003238Z","shell.execute_reply.started":"2024-09-14T14:23:49.997505Z","shell.execute_reply":"2024-09-14T14:23:50.002028Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(65328, 2)\n(65328, 2)\n(65328, 2)\n(65328, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Assuming your 7 DataFrames are stored in a list\ndfs = [df, df1, df2, df3]\n\n# Iterate over each DataFrame and process them\nfor i, df in enumerate(dfs, start=0):\n    # Select relevant columns\n    df = df[['text', 'label']]\n\n    # Sample 15,000 records from the DataFrame\n    sampled_df = df.sample(n=15000, random_state=2092024)\n\n    # Define outcome name\n    outcomename = 'label'\n\n    # Redefine X and Y after sampling\n    X_sampled = sampled_df.drop(columns=outcomename)\n    Y_sampled = sampled_df[outcomename]\n\n    # Split into training and combined validation-test sets (80% train, 20% valid/test)\n    X_train, X_valid_test, y_train, y_valid_test = train_test_split(\n        X_sampled, Y_sampled, test_size=0.2, random_state=2092024, stratify=Y_sampled\n    )\n\n    # Split the combined validation-test set into separate validation and test sets (50% each of the remaining 20%)\n    X_val, X_test, y_val, y_test = train_test_split(\n        X_valid_test, y_valid_test, test_size=0.5, random_state=2092024, stratify=y_valid_test\n    )\n\n    # Assign each split to dynamically named variables (separate for features and labels)\n    globals()[f'X_train_df{i}'] = X_train\n    globals()[f'y_train_df{i}'] = y_train\n    globals()[f'X_val_df{i}'] = X_val\n    globals()[f'y_val_df{i}'] = y_val\n    globals()[f'X_test_df{i}'] = X_test\n    globals()[f'y_test_df{i}'] = y_test\n\n# Now you have X_train_df1, y_train_df1, ..., X_train_df7, y_train_df7, X_val_df1, ..., y_test_df7","metadata":{"id":"LdkYUzgRTZZ3","executionInfo":{"status":"ok","timestamp":1726306821475,"user_tz":-420,"elapsed":2177,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:23:50.004336Z","iopub.execute_input":"2024-09-14T14:23:50.004613Z","iopub.status.idle":"2024-09-14T14:23:50.700937Z","shell.execute_reply.started":"2024-09-14T14:23:50.004568Z","shell.execute_reply":"2024-09-14T14:23:50.700019Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_train_df2.iloc[3,0]","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:30:22.500733Z","iopub.execute_input":"2024-09-14T16:30:22.501642Z","iopub.status.idle":"2024-09-14T16:30:22.508035Z","shell.execute_reply.started":"2024-09-14T16:30:22.501596Z","shell.execute_reply":"2024-09-14T16:30:22.506979Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"\"i think social media has a huge impact on societal norms and values. social media is used by millions of people all around the world, and it has become an integral part of our daily lives. it has changed the way we interact with one another and has also influenced our behavior and beliefs.  one reason why i believe social media has a significant impact on societal norms and values is that it allows people to connect with others who share similar interests and beliefs. this can lead to the creation of echo chambers, where people are exposed only to opinions and views that are similar to their own. as a result, people may become more entrenched in their beliefs and less open to other perspectives.  for instance, if someone follows only conservative political pages on social media, they may become convinced that all liberal views are wrong, and they may be less willing to engage in dialogue or debate with people who hold different political views.  another way that social media has impacted societal norms and values is through the spread of misinformation and fake news. false information that is shared on social media can quickly become viral and influence people's opinions and beliefs. this can be particularly dangerous in situations like political campaigns, where false or misleading information can sway the outcome of an election.  for example, during the 2016 us presidential election, russian operatives used social media to spread false information, which may have influenced the outcome of the election.  in conclusion, social media has a significant impact on societal norms and values. while it has many positive features, such as facilitating communication and connecting people with similar interests, it can also lead to the creation of echo chambers and the spread of misinformation that have the potential to shape public opinion, for worse or for better.\""},"metadata":{}}]},{"cell_type":"code","source":"X_train_df0.iloc[3,0]","metadata":{"execution":{"iopub.status.busy":"2024-09-14T14:29:04.477232Z","iopub.execute_input":"2024-09-14T14:29:04.478076Z","iopub.status.idle":"2024-09-14T14:29:04.483907Z","shell.execute_reply.started":"2024-09-14T14:29:04.478036Z","shell.execute_reply":"2024-09-14T14:29:04.483044Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"\"I think social media has a huge impact on societal norms and values. Social media is used by millions of people all around the world, and it has become an integral part of our daily lives. It has changed the way we interact with one another and has also influenced our behavior and beliefs.  One reason why I believe social media has a significant impact on societal norms and values is that it allows people to connect with others who share similar interests and beliefs. This can lead to the creation of echo chambers, where people are exposed only to opinions and views that are similar to their own. As a result, people may become more entrenched in their beliefs and less open to other perspectives.  For instance, if someone follows only conservative political pages on social media, they may become convinced that all liberal views are wrong, and they may be less willing to engage in dialogue or debate with people who hold different political views.  Another way that social media has impacted societal norms and values is through the spread of misinformation and fake news. False information that is shared on social media can quickly become viral and influence people's opinions and beliefs. This can be particularly dangerous in situations like political campaigns, where false or misleading information can sway the outcome of an election.  For example, during the 2016 US presidential election, Russian operatives used social media to spread false information, which may have influenced the outcome of the election.  In conclusion, social media has a significant impact on societal norms and values. While it has many positive features, such as facilitating communication and connecting people with similar interests, it can also lead to the creation of echo chambers and the spread of misinformation that have the potential to shape public opinion, for worse or for better.\""},"metadata":{}}]},{"cell_type":"code","source":"train_df2_dataset[3]['input_ids']","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:29:54.004883Z","iopub.execute_input":"2024-09-14T16:29:54.005625Z","iopub.status.idle":"2024-09-14T16:29:54.017207Z","shell.execute_reply.started":"2024-09-14T16:29:54.005581Z","shell.execute_reply":"2024-09-14T16:29:54.016300Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  1045,  2228,  2591,  2865,  2038,  1037,  4121,  4254,  2006,\n        23382, 17606,  1998,  5300,  1012,  2591,  2865,  2003,  2109,  2011,\n         8817,  1997,  2111,  2035,  2105,  1996,  2088,  1010,  1998,  2009,\n         2038,  2468,  2019,  9897,  2112,  1997,  2256,  3679,  3268,  1012,\n         2009,  2038,  2904,  1996,  2126,  2057, 11835,  2007,  2028,  2178,\n         1998,  2038,  2036,  5105,  2256,  5248,  1998,  9029,  1012,  2028,\n         3114,  2339,  1045,  2903,  2591,  2865,  2038,  1037,  3278,  4254,\n         2006, 23382, 17606,  1998,  5300,  2003,  2008,  2009,  4473,  2111,\n         2000,  7532,  2007,  2500,  2040,  3745,  2714,  5426,  1998,  9029,\n         1012,  2023,  2064,  2599,  2000,  1996,  4325,  1997,  9052,  8477,\n         1010,  2073,  2111,  2024,  6086,  2069,  2000, 10740,  1998,  5328,\n         2008,  2024,  2714,  2000,  2037,  2219,  1012,  2004,  1037,  2765,\n         1010,  2111,  2089,  2468,  2062,  4372,  7913, 19282,  1999,  2037,\n         9029,  1998,  2625,  2330,  2000,  2060, 15251,  1012,  2005,  6013,\n         1010,  2065,  2619,  4076,  2069,  4603,  2576,  5530,  2006,  2591,\n         2865,  1010,  2027,  2089,  2468,  6427,  2008,  2035,  4314,  5328,\n         2024,  3308,  1010,  1998,  2027,  2089,  2022,  2625,  5627,  2000,\n         8526,  1999,  7982,  2030,  5981,  2007,  2111,  2040,  2907,  2367,\n         2576,  5328,  1012,  2178,  2126,  2008,  2591,  2865,  2038, 19209,\n        23382, 17606,  1998,  5300,  2003,  2083,  1996,  3659,  1997, 28616,\n         2378, 14192,  3370,  1998,  8275,  2739,  1012,  6270,  2592,  2008,\n         2003,  4207,  2006,  2591,  2865,  2064,  2855,  2468, 13434,  1998,\n         3747,  2111,  1005,  1055, 10740,  1998,  9029,  1012,  2023,  2064,\n         2022,  3391,  4795,  1999,  8146,  2066,  2576,  8008,  1010,  2073,\n         6270,  2030, 22369,  2592,  2064, 17812,  1996,  9560,  1997,  2019,\n         2602,  1012,  2005,  2742,  1010,  2076,  1996,  2355,  2149,  4883,\n         2602,  1010,  2845, 25631,  2109,  2591,  2865,  2000,  3659,  6270,\n         2592,  1010,  2029,  2089,  2031,  5105,  1996,  9560,  1997,  1996,\n         2602,  1012,  1999,  7091,  1010,  2591,  2865,  2038,  1037,  3278,\n         4254,  2006, 23382, 17606,  1998,  5300,  1012,  2096,  2009,  2038,\n         2116,  3893,  2838,  1010,  2107,  2004, 25505,  4807,  1998,  7176,\n         2111,  2007,  2714,  5426,  1010,  2009,  2064,  2036,  2599,  2000,\n         1996,  4325,  1997,  9052,  8477,  1998,  1996,  3659,  1997, 28616,\n         2378, 14192,  3370,  2008,  2031,  1996,  4022,  2000,  4338,  2270,\n         5448,  1010,  2005,  4788,  2030,  2005,  2488,  1012,   102,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])"},"metadata":{}}]},{"cell_type":"code","source":"train_df0_dataset[3]['input_ids']","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:30:02.447298Z","iopub.execute_input":"2024-09-14T16:30:02.447696Z","iopub.status.idle":"2024-09-14T16:30:02.460868Z","shell.execute_reply.started":"2024-09-14T16:30:02.447659Z","shell.execute_reply":"2024-09-14T16:30:02.460007Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  1045,  2228,  2591,  2865,  2038,  1037,  4121,  4254,  2006,\n        23382, 17606,  1998,  5300,  1012,  2591,  2865,  2003,  2109,  2011,\n         8817,  1997,  2111,  2035,  2105,  1996,  2088,  1010,  1998,  2009,\n         2038,  2468,  2019,  9897,  2112,  1997,  2256,  3679,  3268,  1012,\n         2009,  2038,  2904,  1996,  2126,  2057, 11835,  2007,  2028,  2178,\n         1998,  2038,  2036,  5105,  2256,  5248,  1998,  9029,  1012,  2028,\n         3114,  2339,  1045,  2903,  2591,  2865,  2038,  1037,  3278,  4254,\n         2006, 23382, 17606,  1998,  5300,  2003,  2008,  2009,  4473,  2111,\n         2000,  7532,  2007,  2500,  2040,  3745,  2714,  5426,  1998,  9029,\n         1012,  2023,  2064,  2599,  2000,  1996,  4325,  1997,  9052,  8477,\n         1010,  2073,  2111,  2024,  6086,  2069,  2000, 10740,  1998,  5328,\n         2008,  2024,  2714,  2000,  2037,  2219,  1012,  2004,  1037,  2765,\n         1010,  2111,  2089,  2468,  2062,  4372,  7913, 19282,  1999,  2037,\n         9029,  1998,  2625,  2330,  2000,  2060, 15251,  1012,  2005,  6013,\n         1010,  2065,  2619,  4076,  2069,  4603,  2576,  5530,  2006,  2591,\n         2865,  1010,  2027,  2089,  2468,  6427,  2008,  2035,  4314,  5328,\n         2024,  3308,  1010,  1998,  2027,  2089,  2022,  2625,  5627,  2000,\n         8526,  1999,  7982,  2030,  5981,  2007,  2111,  2040,  2907,  2367,\n         2576,  5328,  1012,  2178,  2126,  2008,  2591,  2865,  2038, 19209,\n        23382, 17606,  1998,  5300,  2003,  2083,  1996,  3659,  1997, 28616,\n         2378, 14192,  3370,  1998,  8275,  2739,  1012,  6270,  2592,  2008,\n         2003,  4207,  2006,  2591,  2865,  2064,  2855,  2468, 13434,  1998,\n         3747,  2111,  1005,  1055, 10740,  1998,  9029,  1012,  2023,  2064,\n         2022,  3391,  4795,  1999,  8146,  2066,  2576,  8008,  1010,  2073,\n         6270,  2030, 22369,  2592,  2064, 17812,  1996,  9560,  1997,  2019,\n         2602,  1012,  2005,  2742,  1010,  2076,  1996,  2355,  2149,  4883,\n         2602,  1010,  2845, 25631,  2109,  2591,  2865,  2000,  3659,  6270,\n         2592,  1010,  2029,  2089,  2031,  5105,  1996,  9560,  1997,  1996,\n         2602,  1012,  1999,  7091,  1010,  2591,  2865,  2038,  1037,  3278,\n         4254,  2006, 23382, 17606,  1998,  5300,  1012,  2096,  2009,  2038,\n         2116,  3893,  2838,  1010,  2107,  2004, 25505,  4807,  1998,  7176,\n         2111,  2007,  2714,  5426,  1010,  2009,  2064,  2036,  2599,  2000,\n         1996,  4325,  1997,  9052,  8477,  1998,  1996,  3659,  1997, 28616,\n         2378, 14192,  3370,  2008,  2031,  1996,  4022,  2000,  4338,  2270,\n         5448,  1010,  2005,  4788,  2030,  2005,  2488,  1012,   102,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])"},"metadata":{}}]},{"cell_type":"code","source":"X_train_df0.tail()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3O-MxEGlu_T0","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":38,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"1e59da38-2f6e-4943-8da7-4cc3644182f0","execution":{"iopub.status.busy":"2024-09-14T14:23:50.706620Z","iopub.execute_input":"2024-09-14T14:23:50.707116Z","iopub.status.idle":"2024-09-14T14:23:50.716397Z","shell.execute_reply.started":"2024-09-14T14:23:50.707080Z","shell.execute_reply":"2024-09-14T14:23:50.715244Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                                    text\n19782  A Electoral College is a meeting of the electo...\n43523  It is no secret that cars have become an integ...\n11032  Before I get into whether or not FACS is a val...\n17314  In the article \"Driverless Cars Are Coming' It...\n54785  Dear State Senator,  I am writing to you today...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19782</th>\n      <td>A Electoral College is a meeting of the electo...</td>\n    </tr>\n    <tr>\n      <th>43523</th>\n      <td>It is no secret that cars have become an integ...</td>\n    </tr>\n    <tr>\n      <th>11032</th>\n      <td>Before I get into whether or not FACS is a val...</td>\n    </tr>\n    <tr>\n      <th>17314</th>\n      <td>In the article \"Driverless Cars Are Coming' It...</td>\n    </tr>\n    <tr>\n      <th>54785</th>\n      <td>Dear State Senator,  I am writing to you today...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_df1.tail()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vrEBT2MIWtPN","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":36,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"145ef699-a5d8-487b-db5c-dcef984d86ad","execution":{"iopub.status.busy":"2024-09-14T14:23:50.717764Z","iopub.execute_input":"2024-09-14T14:23:50.718107Z","iopub.status.idle":"2024-09-14T14:23:50.729521Z","shell.execute_reply.started":"2024-09-14T14:23:50.718072Z","shell.execute_reply":"2024-09-14T14:23:50.728611Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                                    text\n19782  A Electoral College is a meeting of the electo...\n43523  It is no secret that cars have become an integ...\n11032  Before I get into whether or not FACS is a val...\n17314  In the article \"Driverless Cars Are Coming' It...\n54785  Dear State Senator, I am writing to you today ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19782</th>\n      <td>A Electoral College is a meeting of the electo...</td>\n    </tr>\n    <tr>\n      <th>43523</th>\n      <td>It is no secret that cars have become an integ...</td>\n    </tr>\n    <tr>\n      <th>11032</th>\n      <td>Before I get into whether or not FACS is a val...</td>\n    </tr>\n    <tr>\n      <th>17314</th>\n      <td>In the article \"Driverless Cars Are Coming' It...</td>\n    </tr>\n    <tr>\n      <th>54785</th>\n      <td>Dear State Senator, I am writing to you today ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_df2.tail()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"qV3xUuYOWxHk","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":34,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"34f5fccc-4971-487c-8b4c-2f3a9d3c6e1d","execution":{"iopub.status.busy":"2024-09-14T14:23:50.730624Z","iopub.execute_input":"2024-09-14T14:23:50.730907Z","iopub.status.idle":"2024-09-14T14:23:50.741885Z","shell.execute_reply.started":"2024-09-14T14:23:50.730875Z","shell.execute_reply":"2024-09-14T14:23:50.741074Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                                                    text\n19782  a electoral college is a meeting of the electo...\n43523  it is no secret that cars have become an integ...\n11032  before i get into whether or not facs is a val...\n17314  in the article \"driverless cars are coming' it...\n54785  dear state senator,  i am writing to you today...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19782</th>\n      <td>a electoral college is a meeting of the electo...</td>\n    </tr>\n    <tr>\n      <th>43523</th>\n      <td>it is no secret that cars have become an integ...</td>\n    </tr>\n    <tr>\n      <th>11032</th>\n      <td>before i get into whether or not facs is a val...</td>\n    </tr>\n    <tr>\n      <th>17314</th>\n      <td>in the article \"driverless cars are coming' it...</td>\n    </tr>\n    <tr>\n      <th>54785</th>\n      <td>dear state senator,  i am writing to you today...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_df3.tail()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"1XR_L1_ruueL","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":32,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"0821a002-5619-40d9-ee03-63f854236133","execution":{"iopub.status.busy":"2024-09-14T14:23:50.742925Z","iopub.execute_input":"2024-09-14T14:23:50.743293Z","iopub.status.idle":"2024-09-14T14:23:50.753303Z","shell.execute_reply.started":"2024-09-14T14:23:50.743252Z","shell.execute_reply":"2024-09-14T14:23:50.752406Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                    text\n19782  A Electoral College is a meeting of the electo...\n43523  It is no secret that cars have become an integ...\n11032  Before I get into whether or not FACS is a val...\n17314  In the article Driverless Cars Are Coming It t...\n54785  Dear State Senator  I am writing to you today ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19782</th>\n      <td>A Electoral College is a meeting of the electo...</td>\n    </tr>\n    <tr>\n      <th>43523</th>\n      <td>It is no secret that cars have become an integ...</td>\n    </tr>\n    <tr>\n      <th>11032</th>\n      <td>Before I get into whether or not FACS is a val...</td>\n    </tr>\n    <tr>\n      <th>17314</th>\n      <td>In the article Driverless Cars Are Coming It t...</td>\n    </tr>\n    <tr>\n      <th>54785</th>\n      <td>Dear State Senator  I am writing to you today ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming dfs_original contains your 7 DataFrames: df1, df2, df3, df4, df5, df6, df7\ndfs_original = [df, df1, df2, df3]\n\n# Compare indices of each DataFrame with the next one in the list\nfor i in range(len(dfs_original) - 1):\n    if dfs_original[i].index.equals(dfs_original[i + 1].index):\n        print(f\"DataFrame {i + 1} has the same index as DataFrame {i + 2}.\")\n    else:\n        print(f\"DataFrame {i + 1} does NOT have the same index as DataFrame {i + 2}.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AwipD53Xcuo","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":31,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"6854d3b8-00d8-41f4-db43-d947c38a7a1a","execution":{"iopub.status.busy":"2024-09-14T14:23:50.754379Z","iopub.execute_input":"2024-09-14T14:23:50.754737Z","iopub.status.idle":"2024-09-14T14:23:50.761960Z","shell.execute_reply.started":"2024-09-14T14:23:50.754697Z","shell.execute_reply":"2024-09-14T14:23:50.761022Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"DataFrame 1 has the same index as DataFrame 2.\nDataFrame 2 has the same index as DataFrame 3.\nDataFrame 3 has the same index as DataFrame 4.\n","output_type":"stream"}]},{"cell_type":"code","source":"df1.iloc[32456,0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"95CJXeLzrtvS","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":27,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"e3a84119-1321-490c-fc64-e563f9b213c0","execution":{"iopub.status.busy":"2024-09-14T14:23:50.763212Z","iopub.execute_input":"2024-09-14T14:23:50.763543Z","iopub.status.idle":"2024-09-14T14:23:50.775120Z","shell.execute_reply.started":"2024-09-14T14:23:50.763511Z","shell.execute_reply":"2024-09-14T14:23:50.774160Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"\"Dear Senator , I am writing to express my opinion on the issue of whether to keep the Electoral College or change to a popular vote system for the election of the President of the United States. After carefully considering the information from various sources, I firmly believe that it is in the best interest of our nation to maintain the Electoral College system. Though there are arguments in favor of both systems, the Electoral College provides several important benefits that should not be overlooked. One of the fundamental reasons to retain the Electoral College is the certainty of outcome. As stated in the passage by Judge Richard A. Posner, the winning candidate's share of the Electoral College typically exceeds their share of the popular vote. This ensures that the result of the election is decisive and minimizes the possibility of lengthy legal disputes. In contrast, a direct popular vote system could lead to close elections with no clear winner, which could potentially necessitate time-consuming and costly run-off elections. Additionally, the Electoral College ensures that the President represents a broader range of interests and appeals to a wide spectrum of voters. As Judge Posner points out, the requirement for trans-regional appeal means that candidates must appeal to voters from different regions, rather than focusing solely on winning the most populated areas. This prevents candidates from neglecting the needs and concerns of certain regions, promoting a more balanced representation across the country. Another advantage of the Electoral College is that it encourages candidates to campaign in swing states and adopt policies that address the concerns of these states. Judge Posner correctly notes that voters in swing states are more likely to pay close attention to the campaign and candidates, as they have a greater influence on the outcome. This leads to a more engaged and informed electorate and ensures that candidates do not solely prioritize the interests of heavily democratic or republican states. Moreover, the Electoral College gives smaller states a fairer representation. By providing each state with a minimum number of electors based on their representation in Congress, the system ensures that smaller states are not overshadowed by the larger ones. As mentioned by Judge Posner, this balance of power prevents large states from dominating the election process and guarantees a more equal distribution of attention and resources from presidential candidates. Lastly, the Electoral College avoids the need for run-off elections in cases where no candidate receives a majority of the popular vote. This eliminates the potential for extended election processes and allows for a clear winner to be determined promptly. This certainty and efficiency are essential for maintaining the stability and continuity of our democracy. In conclusion, while there are valid arguments for both the Electoral College and a popular vote system, the benefits provided by the Electoral College cannot be ignored. It ensures a decisive outcome, promotes broader representation, encourages candidates to address the concerns of swing states, safeguards the interests of smaller states, and avoids the need for run-off elections. As such, I urge you to support the retention of the Electoral College in the best interest of our nation. Thank you for considering my perspective on this important matter. I trust that you will weigh all the arguments carefully before making a decision that will impact our electoral system. Sincerely,\""},"metadata":{}}]},{"cell_type":"code","source":"df2.iloc[32456,0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"NBEUIz0srzUU","executionInfo":{"status":"ok","timestamp":1726306821476,"user_tz":-420,"elapsed":24,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"0c93a4be-e845-4d9e-fd04-31aa9ea61e49","execution":{"iopub.status.busy":"2024-09-14T14:23:50.776109Z","iopub.execute_input":"2024-09-14T14:23:50.776471Z","iopub.status.idle":"2024-09-14T14:23:50.783607Z","shell.execute_reply.started":"2024-09-14T14:23:50.776436Z","shell.execute_reply":"2024-09-14T14:23:50.782649Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"\"[your name] [your address] [city, state, zip code] [email address] [phone number] [date]  [senator's name] [senator's address] [city, state, zip code]  dear senator [senator's last name],  i am writing to express my opinion on the issue of whether to keep the electoral college or change to a popular vote system for the election of the president of the united states. after carefully considering the information from various sources, i firmly believe that it is in the best interest of our nation to maintain the electoral college system. though there are arguments in favor of both systems, the electoral college provides several important benefits that should not be overlooked.  one of the fundamental reasons to retain the electoral college is the certainty of outcome. as stated in the passage by judge richard a. posner, the winning candidate's share of the electoral college typically exceeds their share of the popular vote. this ensures that the result of the election is decisive and minimizes the possibility of lengthy legal disputes. in contrast, a direct popular vote system could lead to close elections with no clear winner, which could potentially necessitate time-consuming and costly run-off elections.  additionally, the electoral college ensures that the president represents a broader range of interests and appeals to a wide spectrum of voters. as judge posner points out, the requirement for trans-regional appeal means that candidates must appeal to voters from different regions, rather than focusing solely on winning the most populated areas. this prevents candidates from neglecting the needs and concerns of certain regions, promoting a more balanced representation across the country.  another advantage of the electoral college is that it encourages candidates to campaign in swing states and adopt policies that address the concerns of these states. judge posner correctly notes that voters in swing states are more likely to pay close attention to the campaign and candidates, as they have a greater influence on the outcome. this leads to a more engaged and informed electorate and ensures that candidates do not solely prioritize the interests of heavily democratic or republican states.  moreover, the electoral college gives smaller states a fairer representation. by providing each state with a minimum number of electors based on their representation in congress, the system ensures that smaller states are not overshadowed by the larger ones. as mentioned by judge posner, this balance of power prevents large states from dominating the election process and guarantees a more equal distribution of attention and resources from presidential candidates.  lastly, the electoral college avoids the need for run-off elections in cases where no candidate receives a majority of the popular vote. this eliminates the potential for extended election processes and allows for a clear winner to be determined promptly. this certainty and efficiency are essential for maintaining the stability and continuity of our democracy.  in conclusion, while there are valid arguments for both the electoral college and a popular vote system, the benefits provided by the electoral college cannot be ignored. it ensures a decisive outcome, promotes broader representation, encourages candidates to address the concerns of swing states, safeguards the interests of smaller states, and avoids the need for run-off elections. as such, i urge you to support the retention of the electoral college in the best interest of our nation.  thank you for considering my perspective on this important matter. i trust that you will weigh all the arguments carefully before making a decision that will impact our electoral system.  sincerely,  [your name]\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Training DistilBERT model","metadata":{"id":"KZFFfEZBYFpf"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0T9RFKEkYIIm","executionInfo":{"status":"ok","timestamp":1726306841900,"user_tz":-420,"elapsed":20447,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"f1005b16-59de-460e-d99a-cbe531d33de3","execution":{"iopub.status.busy":"2024-09-14T14:23:50.784722Z","iopub.execute_input":"2024-09-14T14:23:50.785029Z","iopub.status.idle":"2024-09-14T14:24:19.314351Z","shell.execute_reply.started":"2024-09-14T14:23:50.784992Z","shell.execute_reply":"2024-09-14T14:24:19.313379Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf1a0455751845dab5852f95419be11d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ddf62ab35148d4bb5f50d04111d989"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"501be7040dd4484e8b50861e863ba30d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b07bede7fc347ab9e4c36076560a456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc54ae997e074f05b3c8d15cd2aab4fb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts.iloc[index]\n        label = self.labels.iloc[index]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n\n\ntrain_df0_dataset = CustomDataset(X_train_df0['text'], y_train_df0, tokenizer)\ntrain_df1_dataset = CustomDataset(X_train_df1['text'], y_train_df1, tokenizer)\ntrain_df2_dataset = CustomDataset(X_train_df2['text'], y_train_df2, tokenizer)\ntrain_df3_dataset = CustomDataset(X_train_df3['text'], y_train_df3, tokenizer)\n\n\n# For validation datasets\nval_df0_dataset = CustomDataset(X_val_df0['text'], y_val_df0, tokenizer)\nval_df1_dataset = CustomDataset(X_val_df1['text'], y_val_df1, tokenizer)\nval_df2_dataset = CustomDataset(X_val_df2['text'], y_val_df2, tokenizer)\nval_df3_dataset = CustomDataset(X_val_df3['text'], y_val_df3, tokenizer)\n\n# For test datasets\ntest_df0_dataset = CustomDataset(X_test_df0['text'], y_test_df0, tokenizer)\ntest_df1_dataset = CustomDataset(X_test_df1['text'], y_test_df1, tokenizer)\ntest_df2_dataset = CustomDataset(X_test_df2['text'], y_test_df2, tokenizer)\ntest_df3_dataset = CustomDataset(X_test_df3['text'], y_test_df3, tokenizer)\n","metadata":{"id":"1jp9jwg0YP5I","executionInfo":{"status":"ok","timestamp":1726306841901,"user_tz":-420,"elapsed":12,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:24:19.315654Z","iopub.execute_input":"2024-09-14T14:24:19.316288Z","iopub.status.idle":"2024-09-14T14:24:19.328720Z","shell.execute_reply.started":"2024-09-14T14:24:19.316252Z","shell.execute_reply":"2024-09-14T14:24:19.327666Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_df0_dataset[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVihSFHR5s4x","executionInfo":{"status":"ok","timestamp":1726306989335,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"b8bb6ed0-652b-460c-b100-a8680f58ece6","execution":{"iopub.status.busy":"2024-09-14T14:24:19.329900Z","iopub.execute_input":"2024-09-14T14:24:19.330242Z","iopub.status.idle":"2024-09-14T14:24:20.225048Z","shell.execute_reply.started":"2024-09-14T14:24:19.330210Z","shell.execute_reply":"2024-09-14T14:24:20.224038Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101,  2045,  2024,  2116,  2367,  6699,  2008,  2017,  2175,  2083,\n          2006,  1037,  3679,  3978,  1012,  2070,  1997,  2068,  2024, 24820,\n         15323,  1998,  2500,  4995,  1005,  1056,  1012,  2296,  7603,  2008,\n          2017,  2175,  2083,  2064,  2022,  2464,  2011,  2060,  2111,  2083,\n          2115, 13268, 24240,  2015,  1012, 13268, 24240,  2015,  2024,  2590,\n          1999,  2070, 12107,  1010,  2021,  2027,  2024,  2025,  2590,  2005,\n          2495,  1012,  1996, 13268,  2895, 16861,  2291,  2052,  2031,  1037,\n          2843,  1997,  3594,  2006,  1037,  2275,  2005,  1037,  2694,  2565,\n          2030,  2377,  1012,  2009,  2071,  2393,  2191,  1037,  2275,  2448,\n          2062, 18228,  2011,  8285, 18900,  2075,  5622,  5603, 24240,  2015,\n          1998,  2054,  2025,  1012,  1996,  4500,  1997,  2008,  2003,  2995,\n          2005,  2816,  1012,  2045,  2003,  2025,  1037,  2613,  2204,  3114,\n          2005,  2816,  2000,  2224,  4804,  2000,  4965,  6904,  6169,  2138,\n          2025,  2296,  3274,  1999,  1996,  2082,  3791,  2028,  1012,  2009,\n          2453,  2022,  6179,  2000,  2031,  2028,  2006,  2296,  6327,  2341,\n          2000,  1996,  2082,  2000,  4681,  2007,  3036,  2021,  2025,  2006,\n          2082,  7588,  1012,  1999, 20423,  1019,  1997,  1996, 28142,  2009,\n          2163,  1010,  1000,  1999,  2755,  1010,  2057,  4286,  4685,  2023,\n          2168,  8052,  1000, 17208,  1000,  2296,  2154,  1012,  1000,  2008,\n          6251,  2003,  9990,  2008,  4286,  2525,  2079,  2054,  1996,  6904,\n          6169,  2515,  1010,  7297,  2057,  2123,  1005,  1056,  2342,  1037,\n          3274,  2000,  3191,  2256,  6699,  2138,  2057,  2525,  2079,  2061,\n          1012, 13268, 24240,  2015,  2024,  2590,  2000, 10126,  2166,  1012,\n          2009,  2003,  2129,  4286,  3191,  1998,  2393,  3305,  2169, 14573,\n          2121,  1012,  1037,  6904,  6169,  2064,  2022,  6179,  2000,  2393,\n          2582,  3036,  1999,  2816,  1010,  2021,  2025,  2004,  6179,  2000,\n          2393,  2493,  4553,  1012,   102,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': tensor(0)}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available. Using CPU instead.\")\n\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdbF6T9HYoFs","executionInfo":{"status":"ok","timestamp":1726306636060,"user_tz":-420,"elapsed":10,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"49326670-3c05-42b9-c4e2-b33c06f66e26","execution":{"iopub.status.busy":"2024-09-14T14:24:20.226278Z","iopub.execute_input":"2024-09-14T14:24:20.226588Z","iopub.status.idle":"2024-09-14T14:24:20.509611Z","shell.execute_reply.started":"2024-09-14T14:24:20.226556Z","shell.execute_reply":"2024-09-14T14:24:20.508694Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"GPU is available. Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"_Wv-PK97ZLLg","executionInfo":{"status":"ok","timestamp":1726306636060,"user_tz":-420,"elapsed":4,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:24:20.510842Z","iopub.execute_input":"2024-09-14T14:24:20.511229Z","iopub.status.idle":"2024-09-14T14:24:20.516197Z","shell.execute_reply.started":"2024-09-14T14:24:20.511195Z","shell.execute_reply":"2024-09-14T14:24:20.515131Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"id":"JjxuGWTYZfBv","executionInfo":{"status":"ok","timestamp":1726306636060,"user_tz":-420,"elapsed":4,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:30:08.066518Z","iopub.execute_input":"2024-09-14T14:30:08.067158Z","iopub.status.idle":"2024-09-14T14:30:22.659376Z","shell.execute_reply.started":"2024-09-14T14:30:08.067118Z","shell.execute_reply":"2024-09-14T14:30:22.657681Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install --upgrade pyarrow","metadata":{"id":"jQlNi2U9beT6","executionInfo":{"status":"ok","timestamp":1726306636060,"user_tz":-420,"elapsed":4,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:24:20.525880Z","iopub.execute_input":"2024-09-14T14:24:20.526221Z","iopub.status.idle":"2024-09-14T14:24:20.533459Z","shell.execute_reply.started":"2024-09-14T14:24:20.526190Z","shell.execute_reply":"2024-09-14T14:24:20.532508Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")","metadata":{"id":"F-TCwhZFZaNN","executionInfo":{"status":"ok","timestamp":1726306636572,"user_tz":-420,"elapsed":515,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"execution":{"iopub.status.busy":"2024-09-14T14:30:24.866025Z","iopub.execute_input":"2024-09-14T14:30:24.866419Z","iopub.status.idle":"2024-09-14T14:30:26.994798Z","shell.execute_reply.started":"2024-09-14T14:30:24.866384Z","shell.execute_reply":"2024-09-14T14:30:26.993848Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b30fbf766f4010842c291ae7881f37"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset 0","metadata":{"id":"WNnJYFXgffEY"}},{"cell_type":"code","source":"# Don't Show Warning Messages\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YZPzBh7OQMf_","executionInfo":{"status":"ok","timestamp":1726306636572,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"1ae73c7d-ab86-41ab-b9cc-4419846cffb7","execution":{"iopub.status.busy":"2024-09-14T14:30:35.381351Z","iopub.execute_input":"2024-09-14T14:30:35.382258Z","iopub.status.idle":"2024-09-14T14:30:35.386506Z","shell.execute_reply.started":"2024-09-14T14:30:35.382204Z","shell.execute_reply":"2024-09-14T14:30:35.385566Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T15:15:18.342432Z","iopub.execute_input":"2024-09-14T15:15:18.343212Z","iopub.status.idle":"2024-09-14T15:15:18.869521Z","shell.execute_reply.started":"2024-09-14T15:15:18.343153Z","shell.execute_reply":"2024-09-14T15:15:18.868709Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T15:15:33.401396Z","iopub.execute_input":"2024-09-14T15:15:33.401780Z","iopub.status.idle":"2024-09-14T15:15:33.495699Z","shell.execute_reply.started":"2024-09-14T15:15:33.401744Z","shell.execute_reply":"2024-09-14T15:15:33.494682Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df0_dataset,\n    eval_dataset=val_df0_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"2WxUUb8VZPT4","execution":{"iopub.status.busy":"2024-09-14T15:15:48.935085Z","iopub.execute_input":"2024-09-14T15:15:48.935471Z","iopub.status.idle":"2024-09-14T15:33:43.862786Z","shell.execute_reply.started":"2024-09-14T15:15:48.935436Z","shell.execute_reply":"2024-09-14T15:33:43.861879Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 17:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.104006</td>\n      <td>0.974000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.073800</td>\n      <td>0.062876</td>\n      <td>0.984667</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.015800</td>\n      <td>0.072454</td>\n      <td>0.984667</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1125, training_loss=0.04033280807071262, metrics={'train_runtime': 1074.1336, 'train_samples_per_second': 33.515, 'train_steps_per_second': 1.047, 'total_flos': 4768826351616000.0, 'train_loss': 0.04033280807071262, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df0_dataset, batch_size=32, shuffle=False)","metadata":{"id":"k-91cqskQRbZ","execution":{"iopub.status.busy":"2024-09-14T15:33:43.864378Z","iopub.execute_input":"2024-09-14T15:33:43.864684Z","iopub.status.idle":"2024-09-14T15:33:43.870196Z","shell.execute_reply.started":"2024-09-14T15:33:43.864651Z","shell.execute_reply":"2024-09-14T15:33:43.869289Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"7Y7gJhu6QUwq","execution":{"iopub.status.busy":"2024-09-14T15:33:43.871164Z","iopub.execute_input":"2024-09-14T15:33:43.871499Z","iopub.status.idle":"2024-09-14T15:34:00.002279Z","shell.execute_reply.started":"2024-09-14T15:33:43.871466Z","shell.execute_reply":"2024-09-14T15:34:00.001059Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"iovApsGxQXwR","execution":{"iopub.status.busy":"2024-09-14T15:34:00.004932Z","iopub.execute_input":"2024-09-14T15:34:00.005317Z","iopub.status.idle":"2024-09-14T15:34:00.338908Z","shell.execute_reply.started":"2024-09-14T15:34:00.005264Z","shell.execute_reply":"2024-09-14T15:34:00.337833Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.98       636\n           1       0.98      1.00      0.99       864\n\n    accuracy                           0.99      1500\n   macro avg       0.99      0.98      0.99      1500\nweighted avg       0.99      0.99      0.99      1500\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset 1","metadata":{"id":"tD1_TCjFQqbR"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T15:34:00.340276Z","iopub.execute_input":"2024-09-14T15:34:00.340674Z","iopub.status.idle":"2024-09-14T15:34:00.878186Z","shell.execute_reply.started":"2024-09-14T15:34:00.340630Z","shell.execute_reply":"2024-09-14T15:34:00.877256Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T15:34:00.879749Z","iopub.execute_input":"2024-09-14T15:34:00.880480Z","iopub.status.idle":"2024-09-14T15:34:00.978314Z","shell.execute_reply.started":"2024-09-14T15:34:00.880427Z","shell.execute_reply":"2024-09-14T15:34:00.977304Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df1_dataset,\n    eval_dataset=val_df1_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"c_BgysFyQqbX","execution":{"iopub.status.busy":"2024-09-14T15:34:00.979626Z","iopub.execute_input":"2024-09-14T15:34:00.980039Z","iopub.status.idle":"2024-09-14T15:51:57.210871Z","shell.execute_reply.started":"2024-09-14T15:34:00.979994Z","shell.execute_reply":"2024-09-14T15:51:57.209978Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 17:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.059221</td>\n      <td>0.983333</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.074200</td>\n      <td>0.079352</td>\n      <td>0.983333</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.016300</td>\n      <td>0.075002</td>\n      <td>0.984667</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1125, training_loss=0.04068656465742323, metrics={'train_runtime': 1075.3175, 'train_samples_per_second': 33.478, 'train_steps_per_second': 1.046, 'total_flos': 4768826351616000.0, 'train_loss': 0.04068656465742323, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df1_dataset, batch_size=32, shuffle=False)","metadata":{"id":"2-9qjw8fQqbX","execution":{"iopub.status.busy":"2024-09-14T15:51:57.212239Z","iopub.execute_input":"2024-09-14T15:51:57.212928Z","iopub.status.idle":"2024-09-14T15:51:57.218803Z","shell.execute_reply.started":"2024-09-14T15:51:57.212876Z","shell.execute_reply":"2024-09-14T15:51:57.216493Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"ZvgxTJGaQqbX","execution":{"iopub.status.busy":"2024-09-14T15:51:57.220083Z","iopub.execute_input":"2024-09-14T15:51:57.220386Z","iopub.status.idle":"2024-09-14T15:52:13.334775Z","shell.execute_reply.started":"2024-09-14T15:51:57.220355Z","shell.execute_reply":"2024-09-14T15:52:13.333934Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"bgvoQrPJQqbX","execution":{"iopub.status.busy":"2024-09-14T15:52:13.339192Z","iopub.execute_input":"2024-09-14T15:52:13.339542Z","iopub.status.idle":"2024-09-14T15:52:13.585188Z","shell.execute_reply.started":"2024-09-14T15:52:13.339505Z","shell.execute_reply":"2024-09-14T15:52:13.584263Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98       636\n           1       0.97      1.00      0.99       864\n\n    accuracy                           0.98      1500\n   macro avg       0.98      0.98      0.98      1500\nweighted avg       0.98      0.98      0.98      1500\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset 2","metadata":{"id":"zlnLsiOORLOk"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T15:52:13.586210Z","iopub.execute_input":"2024-09-14T15:52:13.586527Z","iopub.status.idle":"2024-09-14T15:52:14.131795Z","shell.execute_reply.started":"2024-09-14T15:52:13.586493Z","shell.execute_reply":"2024-09-14T15:52:14.130802Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T15:52:14.132924Z","iopub.execute_input":"2024-09-14T15:52:14.133237Z","iopub.status.idle":"2024-09-14T15:52:14.225450Z","shell.execute_reply.started":"2024-09-14T15:52:14.133204Z","shell.execute_reply":"2024-09-14T15:52:14.224514Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df2_dataset,\n    eval_dataset=val_df2_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"ZZrmtkXiRLOr","execution":{"iopub.status.busy":"2024-09-14T15:52:14.226784Z","iopub.execute_input":"2024-09-14T15:52:14.227305Z","iopub.status.idle":"2024-09-14T16:10:09.765057Z","shell.execute_reply.started":"2024-09-14T15:52:14.227257Z","shell.execute_reply":"2024-09-14T16:10:09.764120Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 17:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.059499</td>\n      <td>0.986667</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.072500</td>\n      <td>0.095038</td>\n      <td>0.980000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.016800</td>\n      <td>0.076199</td>\n      <td>0.986000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1125, training_loss=0.04018248452080621, metrics={'train_runtime': 1074.6367, 'train_samples_per_second': 33.5, 'train_steps_per_second': 1.047, 'total_flos': 4768826351616000.0, 'train_loss': 0.04018248452080621, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df2_dataset, batch_size=32, shuffle=False)","metadata":{"id":"PD7w4e-eRLOr","execution":{"iopub.status.busy":"2024-09-14T16:10:09.766135Z","iopub.execute_input":"2024-09-14T16:10:09.766432Z","iopub.status.idle":"2024-09-14T16:10:09.771571Z","shell.execute_reply.started":"2024-09-14T16:10:09.766400Z","shell.execute_reply":"2024-09-14T16:10:09.770503Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"tbV-kpmpRLOr","execution":{"iopub.status.busy":"2024-09-14T16:10:09.772803Z","iopub.execute_input":"2024-09-14T16:10:09.773128Z","iopub.status.idle":"2024-09-14T16:10:25.875252Z","shell.execute_reply.started":"2024-09-14T16:10:09.773094Z","shell.execute_reply":"2024-09-14T16:10:25.874444Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"0BynpvM5RLOr","execution":{"iopub.status.busy":"2024-09-14T16:10:25.876448Z","iopub.execute_input":"2024-09-14T16:10:25.876755Z","iopub.status.idle":"2024-09-14T16:10:26.185221Z","shell.execute_reply.started":"2024-09-14T16:10:25.876722Z","shell.execute_reply":"2024-09-14T16:10:26.184355Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98       636\n           1       0.97      1.00      0.98       864\n\n    accuracy                           0.98      1500\n   macro avg       0.98      0.98      0.98      1500\nweighted avg       0.98      0.98      0.98      1500\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset 3","metadata":{"id":"Jqb3IlC6RPNv"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:10:26.187067Z","iopub.execute_input":"2024-09-14T16:10:26.187497Z","iopub.status.idle":"2024-09-14T16:10:26.723657Z","shell.execute_reply.started":"2024-09-14T16:10:26.187451Z","shell.execute_reply":"2024-09-14T16:10:26.722653Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:10:26.724864Z","iopub.execute_input":"2024-09-14T16:10:26.725189Z","iopub.status.idle":"2024-09-14T16:10:26.815173Z","shell.execute_reply.started":"2024-09-14T16:10:26.725156Z","shell.execute_reply":"2024-09-14T16:10:26.814276Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df3_dataset,\n    eval_dataset=val_df3_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"qKOfWjLZRPN1","execution":{"iopub.status.busy":"2024-09-14T16:10:26.816289Z","iopub.execute_input":"2024-09-14T16:10:26.816652Z","iopub.status.idle":"2024-09-14T16:28:21.366946Z","shell.execute_reply.started":"2024-09-14T16:10:26.816617Z","shell.execute_reply":"2024-09-14T16:28:21.366024Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 17:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.036301</td>\n      <td>0.989333</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.090500</td>\n      <td>0.228864</td>\n      <td>0.953333</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.017500</td>\n      <td>0.087997</td>\n      <td>0.982000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1125, training_loss=0.04863801500532362, metrics={'train_runtime': 1073.6362, 'train_samples_per_second': 33.531, 'train_steps_per_second': 1.048, 'total_flos': 4768826351616000.0, 'train_loss': 0.04863801500532362, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df3_dataset, batch_size=32, shuffle=False)","metadata":{"id":"-9Sn_zMZRPN2","execution":{"iopub.status.busy":"2024-09-14T16:28:21.368239Z","iopub.execute_input":"2024-09-14T16:28:21.368615Z","iopub.status.idle":"2024-09-14T16:28:21.374189Z","shell.execute_reply.started":"2024-09-14T16:28:21.368573Z","shell.execute_reply":"2024-09-14T16:28:21.373031Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"BMKSJZvWRPN2","execution":{"iopub.status.busy":"2024-09-14T16:28:21.375481Z","iopub.execute_input":"2024-09-14T16:28:21.375826Z","iopub.status.idle":"2024-09-14T16:28:37.520232Z","shell.execute_reply.started":"2024-09-14T16:28:21.375785Z","shell.execute_reply":"2024-09-14T16:28:37.518932Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"6izA3JDnRPN2","execution":{"iopub.status.busy":"2024-09-14T16:28:37.521688Z","iopub.execute_input":"2024-09-14T16:28:37.522073Z","iopub.status.idle":"2024-09-14T16:28:37.770386Z","shell.execute_reply.started":"2024-09-14T16:28:37.522034Z","shell.execute_reply":"2024-09-14T16:28:37.769481Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97       636\n           1       0.96      1.00      0.98       864\n\n    accuracy                           0.98      1500\n   macro avg       0.98      0.97      0.98      1500\nweighted avg       0.98      0.98      0.98      1500\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training RoBERTa model","metadata":{"id":"Xs5uc5kkSDVa"}},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n\nmodel = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=2)\ntokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-base\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411,"referenced_widgets":["e337dcd644054aadb0fb4d161b6f9ac7","ee2838e62c794d3d904b023f86754dc1","4b09bb8b30b548e3847457af25644d83","61171cad34c54c7cabb0af760d20a587","176998289d3d4307a75ea152e8295edd","e7f93bd4130249df8bf03afd1da6e8cf","3c5fb2e9be564e15908d69ffc3f62c6b","f8be6baba4a0462a97c15a980bb333e1","b17fd0161b0349edb6cfdfe5d355d376","21d03440780f4400b5dff462baccd128","8975030a5fd247129a4c5f2b359c5c36","8cf4e98baf764e98b47a1a0df86639bd","7bff5c6fcd5f4ee6b58a501b3b2bb135","b32ef277f1ba47408c2a16b6a03a3436","4fc779f0ae7f464dbc9a83e17af4ee01","70412a7c8fec4088b9d5cef238b17da0","b7e93c817b9443d38ac69ce17472e44e","a99ebb614dab47af9f6313094376d599","ad1da6c652df42999e48353b60e2762b","1e4624295e0a47bebe7679689ada22e2","65b68359798d438a922eda9157985acb","03aa96c4a70946329bad33131a408e32","99b54b4b17d541ffb349f11425566a2e","a99a50a74f964dd68b79f0cc0c1cf9d9","e4e5318eb1b94194a92e956b76390b36","22aa05cd932743648ad16b13096ceca8","01613ffb80944c7ea2cc49f690a36a90","9a8d3d6441924f759a52dbc6b23966d1","eae0ce29f3864372ba3f67e1673a7dc9","ca70668ad9134ed1ad1bf7d5695c83ed","5edb6b7573644c9cad43176b799d8561","7cbc0a4c732546ca9469fbd7a29e7272","6680f42f2e6f45d1a00281b380217e0f","064e0523dc6e40e4be4bb674d115ad72","d1101f509fef4f788913b2b1d399af6c","321579d846d143d998a13bd4f98a3a05","8fbe446853d54b8fb09f0134f7e7ea8b","c697dc2bef604525bb6a2baaabe8fb84","42386a46180543be8536f685ccb8904e","9f35ad4f3a6644f18af8ab2a38f62119","3ef6561356214dd99edf95d1bb2bcb63","4c55f55aff164ce590567d433c6efe24","678cc680f0644beeb01ff25a697c68cf","c49ca8499a0c436eabb275f21c41f7fa","f06df0a3636a454989b6f5642a6d8450","de5cbe45657149b18bba4fda26a37847","cf04b9831ce645f88dfdffb77829a18d","a1163fb824ae44189840f23fab104197","8860400fd81e4c1caad840872ba7172a","5be4068cdd4f47fab7c125ef18a75e1e","198293a8b0e24c6580c174b13fffe18b","fc1cfd0b49254b318d113ee049dbe31e","04fd2b6a20f14ddbba307ae8da52c14e","992e56a22230425b90843680e20a19ee","47a31b049307458ab0dc2b1ca9cbacfc","e3f4b5c8718541348fff4094632a7fdd","fbc4c426b265491d99c71ac2f8fb6d29","bf4280997d4d4888aa7ffc0d64dffa1a","e5e109c5fb8944048581293cef147aad","76fb1653b91b445ea0f070c781ddb987","79cc175cc88443eb814938ef954cb7fd","bf739cbad0e04267bc1438422c9b6621","ce1886d58dce4b1f9e626a3c75794f0e","b2100ed0f257475ab7fb452f75edd9c9","c32b9e0504244a1682b90f413cb10f7e","dc3a2568a93442408fbbdb57d712aed8"]},"executionInfo":{"status":"ok","timestamp":1726246916838,"user_tz":-420,"elapsed":35896,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"d07d3d7e-9391-447b-81ba-d1674bb69f67","id":"9vVz2AOGSDVg","execution":{"iopub.status.busy":"2024-09-14T16:35:15.771494Z","iopub.execute_input":"2024-09-14T16:35:15.771924Z","iopub.status.idle":"2024-09-14T16:35:31.225132Z","shell.execute_reply.started":"2024-09-14T16:35:15.771885Z","shell.execute_reply":"2024-09-14T16:35:31.224254Z"},"trusted":true},"execution_count":113,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef221b2f154a4de7a8b3f1494f37ccd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1af9af454448444ca2c6ae50b0281cb5"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb7f6f1440547f99da11586ffbf1962"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c520785cde7415ba694d1a903b73430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91c9bb547d2f41b3946a1f56428a086e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02b74bfe62e74135b915cc004755ce5e"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts.iloc[index]\n        label = self.labels.iloc[index]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n\n\ntrain_df0_dataset = CustomDataset(X_train_df0['text'], y_train_df0, tokenizer)\ntrain_df1_dataset = CustomDataset(X_train_df1['text'], y_train_df1, tokenizer)\ntrain_df2_dataset = CustomDataset(X_train_df2['text'], y_train_df2, tokenizer)\ntrain_df3_dataset = CustomDataset(X_train_df3['text'], y_train_df3, tokenizer)\n\n\n# For validation datasets\nval_df0_dataset = CustomDataset(X_val_df0['text'], y_val_df0, tokenizer)\nval_df1_dataset = CustomDataset(X_val_df1['text'], y_val_df1, tokenizer)\nval_df2_dataset = CustomDataset(X_val_df2['text'], y_val_df2, tokenizer)\nval_df3_dataset = CustomDataset(X_val_df3['text'], y_val_df3, tokenizer)\n\n# For test datasets\ntest_df0_dataset = CustomDataset(X_test_df0['text'], y_test_df0, tokenizer)\ntest_df1_dataset = CustomDataset(X_test_df1['text'], y_test_df1, tokenizer)\ntest_df2_dataset = CustomDataset(X_test_df2['text'], y_test_df2, tokenizer)\ntest_df3_dataset = CustomDataset(X_test_df3['text'], y_test_df3, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:35:35.280544Z","iopub.execute_input":"2024-09-14T16:35:35.281475Z","iopub.status.idle":"2024-09-14T16:35:35.295170Z","shell.execute_reply.started":"2024-09-14T16:35:35.281405Z","shell.execute_reply":"2024-09-14T16:35:35.294160Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"train_df2_dataset[3]['input_ids']","metadata":{"execution":{"iopub.status.busy":"2024-09-14T16:36:19.937792Z","iopub.execute_input":"2024-09-14T16:36:19.938771Z","iopub.status.idle":"2024-09-14T16:36:19.966253Z","shell.execute_reply.started":"2024-09-14T16:36:19.938717Z","shell.execute_reply":"2024-09-14T16:36:19.965287Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"tensor([    0,   118,   206,   592,   433,    34,    10,  1307,   913,    15,\n        24032, 14513,     8,  3266,     4,   592,   433,    16,   341,    30,\n         2535,     9,    82,    70,   198,     5,   232,     6,     8,    24,\n           34,   555,    41, 14876,   233,     9,    84,  1230,  1074,     4,\n           24,    34,  1714,     5,   169,    52, 10754,    19,    65,   277,\n            8,    34,    67, 11359,    84,  3650,     8,  9734,     4,  1437,\n           65,  1219,   596,   939,   679,   592,   433,    34,    10,  1233,\n          913,    15, 24032, 14513,     8,  3266,    16,    14,    24,  2386,\n           82,     7,  4686,    19,   643,    54,   458,  1122,  3168,     8,\n         9734,     4,    42,    64,   483,     7,     5,  5012,     9, 23930,\n        16663,     6,   147,    82,    32,  4924,   129,     7,  5086,     8,\n         2728,    14,    32,  1122,     7,    49,   308,     4,    25,    10,\n          898,     6,    82,   189,   555,    55, 24581,    11,    49,  9734,\n            8,   540,   490,     7,    97, 17403,     4,  1437,    13,  4327,\n            6,   114,   951,  3905,   129,  3354,   559,  6052,    15,   592,\n          433,     6,    51,   189,   555,  7013,    14,    70,  6176,  2728,\n           32,  1593,     6,     8,    51,   189,    28,   540,  2882,     7,\n         4949,    11,  6054,    50,  2625,    19,    82,    54,   946,   430,\n          559,  2728,     4,  1437,   277,   169,    14,   592,   433,    34,\n         7284, 24032, 14513,     8,  3266,    16,   149,     5,  2504,     9,\n        23038,     8,  4486,   340,     4,  3950,   335,    14,    16,  1373,\n           15,   592,   433,    64,  1335,   555,  7696,     8,  2712,    82,\n           18,  5086,     8,  9734,     4,    42,    64,    28,  1605,  2702,\n           11,  5458,   101,   559,  6392,     6,   147,  3950,    50, 12030,\n          335,    64, 17980,     5,  4258,     9,    41,   729,     4,  1437,\n           13,  1246,     6,   148,     5,   336,   201,  1939,   729,     6,\n          910, 42472, 20033,   341,   592,   433,     7,  2504,  3950,   335,\n            6,    61,   189,    33, 11359,     5,  4258,     9,     5,   729,\n            4,  1437,    11,  6427,     6,   592,   433,    34,    10,  1233,\n          913,    15, 24032, 14513,     8,  3266,     4,   150,    24,    34,\n          171,  1313,  1575,     6,   215,    25, 23373,  4358,     8,  9809,\n           82,    19,  1122,  3168,     6,    24,    64,    67,   483,     7,\n            5,  5012,     9, 23930, 16663,     8,     5,  2504,     9, 23038,\n           14,    33,     5,   801,     7,  3989,   285,  2979,     6,    13,\n         3007,    50,    13,   357,     4,     2,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1])"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available. Using CPU instead.\")\n\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135860223,"user_tz":-420,"elapsed":422,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"0f571ca1-0e4d-4b97-f55b-325c10eca480","id":"lMHUSv2RSDVh","execution":{"iopub.status.busy":"2024-09-14T16:37:56.591488Z","iopub.execute_input":"2024-09-14T16:37:56.592330Z","iopub.status.idle":"2024-09-14T16:37:56.607907Z","shell.execute_reply.started":"2024-09-14T16:37:56.592288Z","shell.execute_reply":"2024-09-14T16:37:56.607020Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"GPU is available. Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"Yj67ElhVSDVh","execution":{"iopub.status.busy":"2024-09-14T16:38:09.251653Z","iopub.execute_input":"2024-09-14T16:38:09.252260Z","iopub.status.idle":"2024-09-14T16:38:09.256939Z","shell.execute_reply.started":"2024-09-14T16:38:09.252219Z","shell.execute_reply":"2024-09-14T16:38:09.256014Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1726135879721,"user_tz":-420,"elapsed":14357,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"76939915-bb72-420a-ec2a-9fc7f017a437","id":"83BrV2f6SDVh"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting evaluate\n\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n\nCollecting datasets>=2.0.0 (from evaluate)\n\n  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n\nCollecting dill (from evaluate)\n\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n\nCollecting xxhash (from evaluate)\n\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n\nCollecting multiprocess (from evaluate)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.6)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n\nCollecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets, evaluate\n\n  Attempting uninstall: pyarrow\n\n    Found existing installation: pyarrow 14.0.2\n\n    Uninstalling pyarrow-14.0.2:\n\n      Successfully uninstalled pyarrow-14.0.2\n\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n\n\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow"]},"id":"be4fab32b87a4bacb39e834e7bebaa3b"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade pyarrow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135888288,"user_tz":-420,"elapsed":8574,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"61a096a1-b6d0-485a-b5ba-21eab2e1fd4e","id":"gfHVmjxhSDVh"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n\nRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\n\u001b[0m"}]},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")","metadata":{"id":"cjSep-wnSDVi","execution":{"iopub.status.busy":"2024-09-14T16:38:15.621620Z","iopub.execute_input":"2024-09-14T16:38:15.622060Z","iopub.status.idle":"2024-09-14T16:38:16.704645Z","shell.execute_reply.started":"2024-09-14T16:38:15.622000Z","shell.execute_reply":"2024-09-14T16:38:16.703876Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 0","metadata":{"id":"bFWkuOhNSDVi"}},{"cell_type":"code","source":"# Don't Show Warning Messages\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"id":"mEzSxtkRSDVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df0_dataset,\n    eval_dataset=val_df0_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"mkrPMqpFSDVi","execution":{"iopub.status.busy":"2024-09-14T16:38:24.881504Z","iopub.execute_input":"2024-09-14T16:38:24.881921Z","iopub.status.idle":"2024-09-14T16:38:27.968409Z","shell.execute_reply.started":"2024-09-14T16:38:24.881884Z","shell.execute_reply":"2024-09-14T16:38:27.966582Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":120,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[120], line 25\u001b[0m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2295\u001b[0m ):\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3328\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3328\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3334\u001b[0m ):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:410\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:337\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    329\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 337\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    347\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:226\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    223\u001b[0m     past_key_value \u001b[38;5;241m=\u001b[39m (key_layer, value_layer)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_key\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_key_query\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    229\u001b[0m     query_length, key_length \u001b[38;5;241m=\u001b[39m query_layer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], key_layer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 59.12 MiB is free. Process 2949 has 15.83 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 55.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 59.12 MiB is free. Process 2949 has 15.83 GiB memory in use. Of the allocated memory 15.48 GiB is allocated by PyTorch, and 55.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df0_dataset, batch_size=32, shuffle=False)","metadata":{"id":"U41t679hSDVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"LulBXl0MSDVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"valkdWf1SDVi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 1","metadata":{"id":"i8GZBSJ9SDVi"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df1_dataset,\n    eval_dataset=val_df1_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"LLH7_6ydSDVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df1_dataset, batch_size=32, shuffle=False)","metadata":{"id":"lAfCz3SWSDVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"ugipl4xFSDVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"tIdEMiaISDVj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 2","metadata":{"id":"COekFdFPSDVj"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df2_dataset,\n    eval_dataset=val_df2_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"yrunv5ioSDVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df2_dataset, batch_size=32, shuffle=False)","metadata":{"id":"jCt-Jd0LSDVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"UgXvVBaKSDVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"as8gQ9l0SDVj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 3","metadata":{"id":"iskCsCbCSDVj"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df3_dataset,\n    eval_dataset=val_df3_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"FWfAP7iKSDVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df3_dataset, batch_size=32, shuffle=False)","metadata":{"id":"IY_kW_ULSDVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"2GcK7moKSDVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"ex28WlynSDVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training XLNet model","metadata":{"id":"zxLStZU-SD_m"}},{"cell_type":"code","source":"from transformers import XLNetTokenizer, XLNetForSequenceClassification\n\nmodel = XLNetForSequenceClassification.from_pretrained(\"xlnet/xlnet-base-cased\")\ntokenizer = XLNetTokenizer.from_pretrained(\"xlnet/xlnet-base-cased\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201,"referenced_widgets":["df63c69c724342fbb88a93490b95c110","36184cd576324e44ae3f952963618024","632f4511381349a8ad697d7fdf2608c9","45ed83dda15542459bbd0592aa9088dd","06ac108144ff4fbf867a8a72cf9e7471","90b6a6c731d643c885d6824d34ed2928","798c3c8c9b724dcd9c190860d01eebce","3da61f8d29f3421face351bddace0299","968ede3a2f1042c885627cafa99f74ed","dad4ab2ba07f4073b659456822831709","6a793d0b97f54357a5afeb3d774d3935","789adcada9fd414c9262a84f3c8cbda7","4e42c1b4cdf5477789b726f5d43ded25","a244ae4cb8104390a66faa02ff243b72","59a65969b6994bc689df86c295d00785","7ed0cd74c0ac4a37bdc157e6dc973c68","7f06dfe32ef44479be3a5206c54aaf75","acc8caf33def4368b254b6db938757ae","fcbc83a50d004abfa421b7c573a09a1a","6f832f7873a741308575e5e58c6c67c2","38db9badf7194f95aa5fda60f748fd25","670fd28d244c4430a9d803f4ff411bc3","16eefa5766644eb38f3adb530352ebe1","765d68b3a64e4c63aa84675cc39d8d20","841cfc728e7248c98deb372d38927e7b","eaee0b7ecb284a9c91053060c197f4ff","d04fef3813d045c99d06d7659990a776","62aa07e1bafd4c269d2a8c76789a50e5","975f10b92de64fef8a9a0f5b070bdae0","5c1ec72d49424a7fb4ff63c1874762b1","2dc0c41b9b56499e8caf283444b0636d","e541683542ce4cf9af1a6c32fc808331","aafaeb1c444d46e5bef550d61889fae6","b8ac3e00fa984f18a3529168c805cc42","7dcf1cf689d043c3a3e04adeae366877","fbd0d965856b43e68e92a6dcf49ca2b7","703efc9d37be45f2b0cef672ef75242c","f85b0edbf24c49bab4b58ebda65b27b4","b54ce5b89e50453ea2a8795755b45958","9cde3488eec141a887214237a638e096","3fa92cb8a7a44333bf9da906f4348407","26871be981ed4b1985d96202c252ea10","ddbd5683b83a4c96a5e4276f8e20be9e","593c1ae59fc54c4ab93af2c72c231c0d"]},"executionInfo":{"status":"ok","timestamp":1726246929753,"user_tz":-420,"elapsed":7681,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"8a671077-9a3d-4cc0-b089-02d0db4e32b8","id":"celqqCo_SD_n"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df63c69c724342fbb88a93490b95c110"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"789adcada9fd414c9262a84f3c8cbda7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16eefa5766644eb38f3adb530352ebe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ac3e00fa984f18a3529168c805cc42"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts.iloc[index]\n        label = self.labels.iloc[index]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Assuming you have a tokenizer instance already defined\n# Example: tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Create datasets for each DataFrame explicitly\n\n# For train datasets\n\ntrain_df0_dataset = CustomDataset(X_train_df0['text'], y_train_df0, tokenizer)\ntrain_df1_dataset = CustomDataset(X_train_df1['text'], y_train_df1, tokenizer)\ntrain_df2_dataset = CustomDataset(X_train_df2['text'], y_train_df2, tokenizer)\ntrain_df3_dataset = CustomDataset(X_train_df3['text'], y_train_df3, tokenizer)\n\n\n# For validation datasets\nval_df0_dataset = CustomDataset(X_val_df0['text'], y_val_df0, tokenizer)\nval_df1_dataset = CustomDataset(X_val_df1['text'], y_val_df1, tokenizer)\nval_df2_dataset = CustomDataset(X_val_df2['text'], y_val_df2, tokenizer)\nval_df3_dataset = CustomDataset(X_val_df3['text'], y_val_df3, tokenizer)\n\n# For test datasets\ntest_df0_dataset = CustomDataset(X_test_df0['text'], y_test_df0, tokenizer)\ntest_df1_dataset = CustomDataset(X_test_df1['text'], y_test_df1, tokenizer)\ntest_df2_dataset = CustomDataset(X_test_df2['text'], y_test_df2, tokenizer)\ntest_df3_dataset = CustomDataset(X_test_df3['text'], y_test_df3, tokenizer)\n\n# Now you have train_df1_dataset, val_df1_dataset, test_df1_dataset, ..., train_df7_dataset, val_df7_dataset, test_df7_dataset","metadata":{"id":"jIWho6FpSD_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available. Using CPU instead.\")\n\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135860223,"user_tz":-420,"elapsed":422,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"0f571ca1-0e4d-4b97-f55b-325c10eca480","id":"j1E-q_SySD_n"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"GPU not available. Using CPU instead.\n"},{"output_type":"execute_result","execution_count":84,"data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"ctkvtjOmSD_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1726135879721,"user_tz":-420,"elapsed":14357,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"76939915-bb72-420a-ec2a-9fc7f017a437","id":"q74GBV1NSD_n"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting evaluate\n\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n\nCollecting datasets>=2.0.0 (from evaluate)\n\n  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n\nCollecting dill (from evaluate)\n\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n\nCollecting xxhash (from evaluate)\n\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n\nCollecting multiprocess (from evaluate)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.6)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n\nCollecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets, evaluate\n\n  Attempting uninstall: pyarrow\n\n    Found existing installation: pyarrow 14.0.2\n\n    Uninstalling pyarrow-14.0.2:\n\n      Successfully uninstalled pyarrow-14.0.2\n\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n\n\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow"]},"id":"be4fab32b87a4bacb39e834e7bebaa3b"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade pyarrow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135888288,"user_tz":-420,"elapsed":8574,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"61a096a1-b6d0-485a-b5ba-21eab2e1fd4e","id":"Mjku87jTSD_n"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n\nRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\n\u001b[0m"}]},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")","metadata":{"id":"v0Qi7EXqSD_n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 0","metadata":{"id":"o7EEO611SD_n"}},{"cell_type":"code","source":"# Don't Show Warning Messages\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"id":"zT45VL0ZSD_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df0_dataset,\n    eval_dataset=val_df0_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"ftTSoEgySD_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df0_dataset, batch_size=32, shuffle=False)","metadata":{"id":"pV5qVRPcSD_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"1W-4lZXPSD_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"qIyKphckSD_o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 1","metadata":{"id":"iyMp2QRlSD_o"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df1_dataset,\n    eval_dataset=val_df1_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"usAKNP0MSD_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df1_dataset, batch_size=32, shuffle=False)","metadata":{"id":"aRdQUelHSD_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"yrWlbRyhSD_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"OpS1TLjHSD_p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 2","metadata":{"id":"wsWMFGg7SD_p"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df2_dataset,\n    eval_dataset=val_df2_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"EehRGPUqSD_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df2_dataset, batch_size=32, shuffle=False)","metadata":{"id":"1jkjUv6aSD_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"wH0m0g44SD_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"mXR2nVbLSD_p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 3","metadata":{"id":"CJcQitYQSD_p"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df3_dataset,\n    eval_dataset=val_df3_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"BSuTiefvSD_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df3_dataset, batch_size=32, shuffle=False)","metadata":{"id":"fgQyUBlASD_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"04amc29oSD_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"PmilbmtiSD_q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Longformer model","metadata":{"id":"T81t_9MXSE5Q"}},{"cell_type":"code","source":"from transformers import LongformerTokenizer, LongformerForSequenceClassification\n\nmodel_name = \"allenai/longformer-base-4096\"\ntokenizer = LongformerTokenizer.from_pretrained(model_name)\nmodel = LongformerForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233,"referenced_widgets":["fd698aac198c40be9ab3f73418cba61b","57c4c26b556d48dbabb8b48dd9ac701c","88a501fc3a38471cb1cf0d695b6e8863","1c5f7e5b82254bda918b8effcad7174f","e086f6713fe848ae85167b90d2ceebca","8ba9b781ee5b49b1929612342d8d4b78","7a0be6543e774f05b87b7b1c4925a4cb","e29da7ff51fb4ef38c1e5c2cbecc840f","111df05df371458b9291d9fa0fe280b3","968cd9b4762449ac845c22986bde3d46","1bce1184bd324a54b0150a586d3f0d82","a74f9d87f695434289b1d950f35bda4c","3188f44e42574908b11bcc35debc3556","8b49d14e52ba43659c02cae97cdb20d2","c49deae9c3c34d85b4f7ffc51349775d","13d0b5547cad4cab93c4de80f2179e6a","8d237da2ee944257b5db659b36c81266","8278795127684ab4878db1a6d634e63f","6c7e810c0fa645ec8cfb64bc8a104ad8","1773ef07fff444029a0090200c59e14b","801e28b6bea84629925098534f0c8614","f46d518f6cdb44cd99d61d6e288c40e8","9d49f794ac624903ae67292c04295ee9","78380aa9836849fbb40ff31be28aa30d","eafbeb7aecfc4b30b5d3d6d81162bb94","039c8cf3fd634607bee706a0df38bacc","84c42baac46d438f885f6453038967d5","b041902497ee40a9977ad4c1db8739df","9d93eeb89d814ad6b1de0e9ac5f768a4","ac6ba53bc9794279b5e119b4538a46ba","4b71866b5aef4e96b2011b6c2f87a761","7df8a7a4bd4c40b5b8dd298105498fb3","8f1d9d7012bb43d8a7e07252115d4a4b","c71bc8105eb744418415cf80a0bca318","5069af5ddc4646469f22dac5c66c0c5c","5b7f8cc85b794e559b4e06cc98aeda38","f3c704c21ba74e4fa3714848096d418f","e9913a1416784811b255c42575a61678","28e1e93cb81649ca992ef4478eb2b9a1","416e90c4fce54364b646218b65d06373","354cf1af785a4485ae8b9e64730bc972","da8c1b478d8f4af184830aa083168e30","afb1cd05c58246cc9d05e3f636979912","9308cd29d0224ae991604144f69c3e3b","ddec840c0cb0470d9a9e1b4e459d5db8","2f9356e7a2d34c75802e539e210f18cc","5fe7a13a5f9d4302b5138a7ef95ac24b","c8f2cd753475466fa6a887b19136e9a4","45118e3b04894d00921afbce1dbe04dc","5ed7b6bbd488434a8eb29d6c4d1a434e","37c535f528ba4526a04e35b18fb4f9e4","3979387eec814123a3d6284358704c46","4942a6a865eb45d4bb9fb3b4b94635b5","226543d95ae442a2af6b0f2c10f3d79f","035c19b2f8374441a665d7a5c7060cf9"]},"executionInfo":{"status":"ok","timestamp":1726247216064,"user_tz":-420,"elapsed":12936,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"3dd64e6a-387a-4815-c30f-7c67c562221a","id":"69OB1V1ZSE5Q"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd698aac198c40be9ab3f73418cba61b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74f9d87f695434289b1d950f35bda4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d49f794ac624903ae67292c04295ee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71bc8105eb744418415cf80a0bca318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddec840c0cb0470d9a9e1b4e459d5db8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts.iloc[index]\n        label = self.labels.iloc[index]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Assuming you have a tokenizer instance already defined\n# Example: tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Create datasets for each DataFrame explicitly\n\n# For train datasets\n\ntrain_df0_dataset = CustomDataset(X_train_df0['text'], y_train_df0, tokenizer)\ntrain_df1_dataset = CustomDataset(X_train_df1['text'], y_train_df1, tokenizer)\ntrain_df2_dataset = CustomDataset(X_train_df2['text'], y_train_df2, tokenizer)\ntrain_df3_dataset = CustomDataset(X_train_df3['text'], y_train_df3, tokenizer)\n\n\n# For validation datasets\nval_df0_dataset = CustomDataset(X_val_df0['text'], y_val_df0, tokenizer)\nval_df1_dataset = CustomDataset(X_val_df1['text'], y_val_df1, tokenizer)\nval_df2_dataset = CustomDataset(X_val_df2['text'], y_val_df2, tokenizer)\nval_df3_dataset = CustomDataset(X_val_df3['text'], y_val_df3, tokenizer)\n\n# For test datasets\ntest_df0_dataset = CustomDataset(X_test_df0['text'], y_test_df0, tokenizer)\ntest_df1_dataset = CustomDataset(X_test_df1['text'], y_test_df1, tokenizer)\ntest_df2_dataset = CustomDataset(X_test_df2['text'], y_test_df2, tokenizer)\ntest_df3_dataset = CustomDataset(X_test_df3['text'], y_test_df3, tokenizer)\n\n# Now you have train_df1_dataset, val_df1_dataset, test_df1_dataset, ..., train_df7_dataset, val_df7_dataset, test_df7_dataset","metadata":{"id":"PWQvvI_WSE5Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available. Using CPU instead.\")\n\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135860223,"user_tz":-420,"elapsed":422,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"0f571ca1-0e4d-4b97-f55b-325c10eca480","id":"IvLZw-XVSE5Q"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"GPU not available. Using CPU instead.\n"},{"output_type":"execute_result","execution_count":84,"data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"ora9KPSpSE5Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1726135879721,"user_tz":-420,"elapsed":14357,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"76939915-bb72-420a-ec2a-9fc7f017a437","id":"-XSlWJjlSE5R"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting evaluate\n\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n\nCollecting datasets>=2.0.0 (from evaluate)\n\n  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n\nCollecting dill (from evaluate)\n\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n\nCollecting xxhash (from evaluate)\n\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n\nCollecting multiprocess (from evaluate)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.6)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n\nCollecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets, evaluate\n\n  Attempting uninstall: pyarrow\n\n    Found existing installation: pyarrow 14.0.2\n\n    Uninstalling pyarrow-14.0.2:\n\n      Successfully uninstalled pyarrow-14.0.2\n\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n\n\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow"]},"id":"be4fab32b87a4bacb39e834e7bebaa3b"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade pyarrow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135888288,"user_tz":-420,"elapsed":8574,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"61a096a1-b6d0-485a-b5ba-21eab2e1fd4e","id":"Y_4_hnyJSE5R"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n\nRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\n\u001b[0m"}]},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")","metadata":{"id":"xOltEsp0SE5R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 0","metadata":{"id":"wdqy013pSE5R"}},{"cell_type":"code","source":"# Don't Show Warning Messages\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"id":"eSoA40HYSE5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df0_dataset,\n    eval_dataset=val_df0_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"h5x5joUWSE5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df0_dataset, batch_size=32, shuffle=False)","metadata":{"id":"E1GoiLDiSE5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"Pt7ZdEQqSE5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"v0SiIVaxSE5S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 1","metadata":{"id":"5UtRDH7hSE5S"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df1_dataset,\n    eval_dataset=val_df1_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"O9gcmdM1SE5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df1_dataset, batch_size=32, shuffle=False)","metadata":{"id":"quyWQtXwSE5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"nGxodK88SE5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"1QJa3NbBSE5S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 2","metadata":{"id":"Ds34040ZSE5S"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df2_dataset,\n    eval_dataset=val_df2_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"Ieag182lSE5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df2_dataset, batch_size=32, shuffle=False)","metadata":{"id":"XnoWmp4sSE5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"UCZ6B5FjSE5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"yFDbnrpgSE5T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 3","metadata":{"id":"fH3lycGfSE5T"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df3_dataset,\n    eval_dataset=val_df3_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"lEwimFNDSE5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df3_dataset, batch_size=32, shuffle=False)","metadata":{"id":"I35-wwBRSE5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"QtI170kASE5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"MLXJCM44SE5T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training LSTM model","metadata":{"id":"bPyMLrJ_SFuB"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379,"referenced_widgets":["07d2b3f6da78420aa6e886391348e25c","37f889bd8b284a45a9ae0fe8a7b7ccd4","2b49dcacdae947c2b4a49fae02caa3c2","15b318529d7c416bb4618971a6c89539","f8bd34a21cba498bb24b6a45631c3c68","7436340be80f4c55a0da4dae0d281b20","7e44de7c7d1a4520bed1b4efc07b7e62","b29d32d84d994a48a072ee68042313c3","3028f642364e4895bdb8665cdfd213ef","1af008ad0189405fba59c55a9dc8a7f4","321ab50ab7e04e0787fbf4ef443e5b4d","f37a36f03c1542ca877c867af4b3e13e","7cd5875ab0734bf1870ed3c1f670eb51","ccc7adbdb1144b6fa0f964b5f771ddc1","1c40860e295742a986194a4d6e2f1769","baf092e348a849119afb1886f87908ef","f9daf729df60414f948e2819217efbfd","3c183a90579a4b6787b4427d4656551f","8785f75c2bf844049cc3fcb4b057a0dd","8eca75e89efa4846bc58a6f714d94640","2f1954fd1557492e9db8f1105aa5f1e0","60b8a9b3f12b469b8d3e9e056e573921","cdc51d79b3684e459e67cb8aef35c3de","51e92497811e46f79f3e8d9c898ec7f7","79b2383da1f54e85a3c19f72cdf39174","01c08f057fc24143b4a301f981718da6","b16c4892c5984f78aa6fa53da74a32a9","a7b26d2c705a40848ba1cbbfe4a38fe7","3e92abc2826f4feabe96d9d8fe559b84","cbd9803896314142bbd55cb79ca5a3ea","b7dfe41eb447469ba86951dd02a32db1","04ec1ec8678e4b9fbc7fe402adbe3dbb","e7fdb0522248449986fdf76ab263f104","063febd1a77142dd862fc03a66a98c42","40567428272c4f2ba9799b5e0dcb592c","7bfd5439a9f94e77a1321428bf53e350","5339d1fff380453cbb54b85a4dcd6faf","6d842625b21644639451447bea69e8fc","e1a63c7f4e4a460db8f837d5ee2da1fd","d3013207622c449792f2b8576a5710b7","afb42731e20145fa98a5ef94743ea73a","cf062e4420f4410eb761d75d6ffb0618","62f6d4a39c8e41378b3f60fb5510ceb4","9406115c901a4426b318ab95e6b57f88","24ec2b147d2245f999de27e71223c683","a0328b9de2bf48799ce11f421a152ce3","0b0bd8918fac4cae91da2a45c18cfffe","c7a2a13f53534eafabbc783f502277a7","59043b9d47ba4366941a1200ef5b0b20","be38c1df0cd04e00882bf0db57434dfd","dc1cff08a9794c00884f33044381e5db","11fd034c002e4d8c843e8b5069a9da6b","5d30530ca8a94bf9a5f4aaffc414c85a","846d0061d75a474890aaced856346d31","9840f472027f409693a47f6f389e2741"]},"executionInfo":{"status":"ok","timestamp":1726135546742,"user_tz":-420,"elapsed":21631,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"1238967e-e3c0-40c6-f1f5-c4aac45b8d21","id":"P_5jlckOSFuI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n\nThe secret `HF_TOKEN` does not exist in your Colab secrets.\n\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n\nYou will be able to reuse this secret in all of your notebooks.\n\nPlease note that authentication is recommended but still optional to access public models or datasets.\n\n  warnings.warn(\n"},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d2b3f6da78420aa6e886391348e25c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f37a36f03c1542ca877c867af4b3e13e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdc51d79b3684e459e67cb8aef35c3de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"063febd1a77142dd862fc03a66a98c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ec2b147d2245f999de27e71223c683"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts.iloc[index]\n        label = self.labels.iloc[index]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Assuming you have a tokenizer instance already defined\n# Example: tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Create datasets for each DataFrame explicitly\n\n# For train datasets\n\ntrain_df0_dataset = CustomDataset(X_train_df0['text'], y_train_df0, tokenizer)\ntrain_df1_dataset = CustomDataset(X_train_df1['text'], y_train_df1, tokenizer)\ntrain_df2_dataset = CustomDataset(X_train_df2['text'], y_train_df2, tokenizer)\ntrain_df3_dataset = CustomDataset(X_train_df3['text'], y_train_df3, tokenizer)\n\n\n# For validation datasets\nval_df0_dataset = CustomDataset(X_val_df0['text'], y_val_df0, tokenizer)\nval_df1_dataset = CustomDataset(X_val_df1['text'], y_val_df1, tokenizer)\nval_df2_dataset = CustomDataset(X_val_df2['text'], y_val_df2, tokenizer)\nval_df3_dataset = CustomDataset(X_val_df3['text'], y_val_df3, tokenizer)\n\n# For test datasets\ntest_df0_dataset = CustomDataset(X_test_df0['text'], y_test_df0, tokenizer)\ntest_df1_dataset = CustomDataset(X_test_df1['text'], y_test_df1, tokenizer)\ntest_df2_dataset = CustomDataset(X_test_df2['text'], y_test_df2, tokenizer)\ntest_df3_dataset = CustomDataset(X_test_df3['text'], y_test_df3, tokenizer)\n\n# Now you have train_df1_dataset, val_df1_dataset, test_df1_dataset, ..., train_df7_dataset, val_df7_dataset, test_df7_dataset","metadata":{"id":"ZHMhCyCZSFuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available. Using CPU instead.\")\n\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135860223,"user_tz":-420,"elapsed":422,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"0f571ca1-0e4d-4b97-f55b-325c10eca480","id":"hzZJgwWISFuJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"GPU not available. Using CPU instead.\n"},{"output_type":"execute_result","execution_count":84,"data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"6M6Ar1DUSFuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1726135879721,"user_tz":-420,"elapsed":14357,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"76939915-bb72-420a-ec2a-9fc7f017a437","id":"Zvs5mlQLSFuJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting evaluate\n\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n\nCollecting datasets>=2.0.0 (from evaluate)\n\n  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n\nCollecting dill (from evaluate)\n\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n\nCollecting xxhash (from evaluate)\n\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n\nCollecting multiprocess (from evaluate)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.6)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n\nCollecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets, evaluate\n\n  Attempting uninstall: pyarrow\n\n    Found existing installation: pyarrow 14.0.2\n\n    Uninstalling pyarrow-14.0.2:\n\n      Successfully uninstalled pyarrow-14.0.2\n\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n\n\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow"]},"id":"be4fab32b87a4bacb39e834e7bebaa3b"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade pyarrow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726135888288,"user_tz":-420,"elapsed":8574,"user":{"displayName":"Sirapop Narkgaemthong","userId":"01146187031168577809"}},"outputId":"61a096a1-b6d0-485a-b5ba-21eab2e1fd4e","id":"vWlGeFFFSFuJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n\nRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\n\u001b[0m"}]},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")","metadata":{"id":"T4s3WUm5SFuJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 0","metadata":{"id":"9Sj1iSWRSFuJ"}},{"cell_type":"code","source":"# Don't Show Warning Messages\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"id":"dafQWKl0SFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df0_dataset,\n    eval_dataset=val_df0_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"1u79_diwSFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df0_dataset, batch_size=32, shuffle=False)","metadata":{"id":"bYqIzHE8SFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"GIB1Zh_TSFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"xeKb9YAzSFuK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 1","metadata":{"id":"gYUeJqAaSFuK"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df1_dataset,\n    eval_dataset=val_df1_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"duQ539zPSFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df1_dataset, batch_size=32, shuffle=False)","metadata":{"id":"qLP3I_aoSFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"QXZPSHsBSFuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"Mv1_IVG-SFuK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 2","metadata":{"id":"q2lBVUktSFuL"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df2_dataset,\n    eval_dataset=val_df2_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"4fMKOJMBSFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df2_dataset, batch_size=32, shuffle=False)","metadata":{"id":"GMVd82W9SFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"SH5j4XDxSFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"fxjAD26NSFuL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 3","metadata":{"id":"4X30m60rSFuL"}},{"cell_type":"code","source":"from transformers import AdamW,EarlyStoppingCallback,TrainerCallback,get_linear_schedule_with_warmup\n\n# Freeze all layers except for pre_classifier, classifier, and FFN layers\nfor name, param in model.named_parameters():\n    if not any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = False\n\n# Ensure that the pre_classifier, classifier, and FFN layers are unfrozen\nfor name, param in model.named_parameters():\n    if any(substring in name for substring in ['pre_classifier', 'classifier', 'transformer']):\n        param.requires_grad = True\n\ntraining_args = TrainingArguments(\n    eval_strategy=\"epoch\",\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_strategy=\"steps\",\n    save_steps = 1000,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df3_dataset,\n    eval_dataset=val_df3_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"id":"Su-gYKKPSFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Assuming you've already created your test_dataset\ntest_loader = DataLoader(test_df3_dataset, batch_size=32, shuffle=False)","metadata":{"id":"cs3Gv4bwSFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nmodel.eval()  # Set the model to evaluation mode\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        _, predictions = torch.max(outputs.logits, dim=1)\n\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays\ny_pred = np.array(all_predictions)\ny_true = np.array(all_true_labels)","metadata":{"id":"3GAVNRhKSFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"Xa7HDxt0SFuL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. LoRA or Freezing layers or full fine-tuning\n\n- LoRA like adapter to based-model, no train at based model just only in adapter\n- Freeze layer, freeze the weights of some layer and retrain other layers\n- Full, retrain all parameters\n\n\n\n","metadata":{"id":"MTm7sf27U24v"}},{"cell_type":"markdown","source":"## Sample to smaller size and training/validation/test split","metadata":{"id":"J4UXVLUwSOT1"}},{"cell_type":"code","source":"#df1 = df.sample(n = 15000,random_state = 192024)\n#df1.shape","metadata":{"id":"LMRLQJ4JSWmj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from sklearn.model_selection import train_test_split\n\ndf1 = df1[['text','label']]\n\noutcomename = 'label'\nX = df1.drop(columns = outcomename)\nY = df1[outcomename]\n\nfeaturename = X.columns\noutcome_value = [\"0\",\"1\"]\nX.head()'''","metadata":{"id":"D5TFRErDSyu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''X_train, X_valid_test, y_train, y_valid_test = train_test_split(X, Y, test_size = 0.2, random_state = 192024,stratify = Y)\nprint('training set = {} records, test_vali set= {} records'.format(X_train.shape[0],X_valid_test.shape[0]))\nprint('training set = {} records, test_vali set= {} records'.format(y_train.shape[0],y_valid_test.shape[0]))'''","metadata":{"id":"J7mB19tNTVe6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''X_valid, X_test, y_valid, y_test = train_test_split(X_valid_test, y_valid_test, test_size = 0.5, random_state = 192024,stratify = y_valid_test)\nprint('validation set = {} records, test set= {} records'.format(X_valid.shape[0],X_test.shape[0]))\nprint('validation set = {} records, test set= {} records'.format(y_valid.shape[0],y_test.shape[0]))'''","metadata":{"id":"ameN4LWRTfiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JKkXFYFhVbio"},"execution_count":null,"outputs":[]}]}